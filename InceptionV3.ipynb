{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic python packages\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom collections import defaultdict\nimport glob\n\n# General machine learning packages\nfrom sklearn.model_selection import train_test_split\n\n# Packages related to images\nfrom PIL import Image\nimport PIL\n\n# Packages for neural networks\nimport tensorflow as tf\nfrom tensorflow.keras import datasets, layers, models\nfrom keras.layers import Activation, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Embedding\nfrom keras.layers import Dense, GlobalAveragePooling2D, Convolution2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom tensorflow.keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Paths to different folders/files\nimage_dir = \"../input/amldata/train_set/train_set\"\ntest_image_dir = \"../input/amldata/test_set\"\nlabels_file = \"../input/amldata/train_labels.csv\"\ntraining_path = '../input/amldata/training_data/'\nvalidation_path = '../input/amldata/validation_data/'\n\nimg_size = (250, 250) #Size of the input of the neural networks\nIMG_SHAPE = img_size + (3,)\nbatch_size = 32\nn_labels = 80\nlabels = pd.read_csv(labels_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(image):\n    image = tf.cast(image, tf.float32)\n    image = (image / 127.5) - 1\n    return image\n\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=normalize,\n    shear_range=2,\n    featurewise_center=False,  # set input mean to 0 over the dataset\n    samplewise_center=False,  # set each sample mean to 0\n    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n    samplewise_std_normalization=False,  # divide each input by its std\n    zca_whitening=False,  # apply ZCA whitening\n    rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip=True,  # randomly flip images\n    vertical_flip=True, # randomly flip images\n    zoom_range=[.8, 1],\n    brightness_range=[0.6,1.3],\n    channel_shift_range=30,\n    fill_mode='reflect')\n\ntest_datagen = ImageDataGenerator(\n        preprocessing_function=normalize)\n\ntrain_generator = train_datagen.flow_from_directory(\n        training_path,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        validation_path,\n        target_size=img_size,\n        batch_size=batch_size,\n        shuffle=True,\n        class_mode='categorical')\n\ntest_generator = test_datagen.flow_from_directory(\n        test_image_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, steps_per_epoch=150, epochs=3, validation_steps=20, workers=7, checkpoint_loc=\"\"):\n    \"\"\"\n    Trains a given model\n\n    :steps_per_epoch: Amount of batches uploaded per epoch. Cant be higher than +- 200\n    :epochs: Amount of times the model trains on the data\n    :validation_steps: Amount of batches used for validation. Cant be higher than +- 50\n    :workers: Amount of processes used to load the data\n    :checkpoint_loc: Place for the model checkpoints to be saved\n    :return: The trained model and some training data\n    \"\"\" \n    # Create a callback that saves the model's weights\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_loc,\n                                                     monitor='acc',\n                                                     save_weights_only=True)\n#     cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_loc, \n#                                                      monitor='acc', \n#                                                      save_weights_only=True, \n#                                                      save_best_only=True, \n#                                                      mode='max')\n    inception_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n    begin_time = datetime.datetime.now()\n    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_generator, validation_steps=validation_steps, workers=workers, callbacks=[cp_callback, inception_early_stopping], verbose=1)\n    print(datetime.datetime.now() - begin_time)\n    return (model, history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_context(\"poster\") \nplt.style.use('seaborn-poster')\n    \ndef plot_history(history, file_name): \n    #Plots the training data. \n    plt.plot(history.history['accuracy'], label='accuracy', linewidth=10) \n    plt.plot(history.history['val_accuracy'], label = 'val_accuracy', linewidth=10) \n    plt.yticks(fontsize=50) \n    plt.xticks(fontsize=50) \n    plt.xlabel('Epoch', fontsize=50) \n    plt.ylabel('Accuracy', fontsize=50) \n    plt.legend(loc='lower right', prop={'size': 40}) \n    plt.savefig(file_name) \n    plt.show()\n     \ndef plot_multiple_histories(histories, labels, file_name): \n    for l in labels: \n        total = [] \n        for h in histories: \n            total = total + h.history[l] \n        if l[:3] == 'val': \n            l = \"validation \" + l[4:] \n        plt.plot(total, label=l, linewidth=10) \n     \n    plt.yticks(fontsize=50) \n    plt.xticks(fontsize=50) \n    plt.xlabel('Epoch', fontsize=50) \n    plt.ylabel('Accuracy', fontsize=50) \n    plt.legend(loc='lower right', prop={'size': 40}) \n    plt.savefig(file_name) \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history, file_name):\n    #Plots the training data.\n    plt.plot(history.history['loss'], label='loss', linewidth=10)\n    plt.plot(history.history['val_loss'], label = 'val_loss', linewidth=10)\n    plt.yticks(fontsize=50) \n    plt.xticks(fontsize=50) \n    plt.xlabel('Epoch', fontsize=50) \n    plt.ylabel('Loss', fontsize=50) \n    plt.legend(loc='upper right', prop={'size': 40}) \n    plt.savefig(file_name) \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(n_labels):\n    InceptionV3_model = tf.keras.applications.InceptionV3(input_shape = IMG_SHAPE, weights = 'imagenet', include_top=False)\n    for layer in InceptionV3_model.layers[:249]:\n       layer.trainable = False\n    for layer in InceptionV3_model.layers[249:]:\n       layer.trainable = True\n    x = InceptionV3_model.output\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    pred = Dense(n_labels, activation='softmax')(x)\n    model = Model(inputs = InceptionV3_model.input, outputs = pred)\n    \n    for layer in model.layers[-8:]:\n        layer.trainable=True\n        \n    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005), \n                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1), \n                  metrics=['accuracy'])\n    \n    return model\n\nmodel = make_model(n_labels)\nmodel.load_weights(\"./Model_weights/\")\n# InceptionResNetV2model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = train_model(model, steps_per_epoch=150, epochs=30, validation_steps=50, checkpoint_loc=\"./Model_weights/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history60, 'InceptionV3_accuracy.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(history60, 'InceptionV3_loss.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_test(model):\n    preds = model.predict(test_generator)\n    preds_cls_idx = preds.argmax(axis=-1)\n    idx_to_cls = {v: k for k, v in train_generator.class_indices.items()}\n    preds_cls = np.vectorize(idx_to_cls.get)(preds_cls_idx)\n    filenames_to_cls = list(zip(test_generator.filenames, preds_cls))\n    \n    l = []\n    n = []\n    for p in filenames_to_cls:\n        n.append(p[0].split(\"/\")[-1])\n        l.append(p[1])\n    return pd.DataFrame(list(zip(n, l)), columns=['img_name','label'])\n\n# model.load_weights(\"./Model_weights/\")\nres = predict_test(model)\nres.to_csv(\"submission2.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}