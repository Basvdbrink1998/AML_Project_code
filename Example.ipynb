{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic python packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "# General machine learning packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Packages related to images\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "# Packages for neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Embedding\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU works\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths to different folders/files\n",
    "image_dir = \"../train_set/train_set\"\n",
    "test_image_dir = \"../test_set/test_set\"\n",
    "labels_file = \"../train_labels.csv\"\n",
    "training_path = '../training_data/'\n",
    "validation_path = '../validation_data/'\n",
    "\n",
    "img_size = (200, 200) #Size of the input of the neural networks\n",
    "IMG_SHAPE = img_size + (3,)\n",
    "batch_size = 32\n",
    "n_labels = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(labels_file)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images(img_names, n_x=2, n_y=2, seed=0):\n",
    "    \"\"\"\n",
    "    Plots random images from de data set in a n_x by n_y grid\n",
    "\n",
    "    :image_names: List with the names of all images\n",
    "    :n_x: Height of the grid\n",
    "    :n_x: Width of the grid\n",
    "    :seed: Seed for the random sample\n",
    "    :return: nothing\n",
    "    \"\"\" \n",
    "    f, axs = plt.subplots(n_x, n_y)\n",
    "    sample = img_names.sample(n_x * n_y, random_state=seed)\n",
    "    c = 0\n",
    "    for x in range(n_x):\n",
    "        for y in range(n_y):\n",
    "            img = plt.imread(image_dir + \"/\" + sample.iloc[c])\n",
    "            axs[x, y].imshow(img)\n",
    "            axs[x, y].axis('off')\n",
    "            c += 1\n",
    "\n",
    "plot_random_images(labels[\"img_name\"], 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image size\n",
    "Most machine learning requires that the input is always of the same size. Because our images are not always of the same size. We have to resize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_names, img_dir, new_img_dir):\n",
    "    #Deprecated, replaced by the flow from directory\n",
    "    for img in img_names:\n",
    "        Image.open(img_dir + \"/\" + img).resize(img_size).save(new_img_dir + \"/\" + img)\n",
    "\n",
    "# resize_images(labels[\"img_name\"], image_dir, resized_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split\n",
    "To test our models locally, we must split our data into a train and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(labels[\"img_name\"].to_numpy(), labels[\"label\"].to_numpy(), test_size=0.2, random_state=42)\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformat data for learning\n",
    "To be able to load the data with a generator. We must split the training and validation data and place them into a folder based on their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_folders(image_path, image_names, image_labels, destination_path):\n",
    "    \"\"\"\n",
    "    Splits a single folder with images into multiple folders where images are placed based on their labels.\n",
    "\n",
    "    :image_path: path to the folder with the images\n",
    "    :image_names: A numpy array with the names of all images\n",
    "    :image_labels: A numpy array with the labels of all images\n",
    "    :destination_path: Path of the folder where the images are placed into\n",
    "    :return: Nothing\n",
    "    \"\"\" \n",
    "    for i in range(len(image_names)):\n",
    "        # Check if the directory exists. Else, make one\n",
    "        isExist = os.path.exists(destination_path + str(image_labels[i]))\n",
    "        if not isExist:\n",
    "            os.makedirs(destination_path + str(image_labels[i]))\n",
    "            \n",
    "        # Copy the image\n",
    "        img = Image.open(image_path + \"/\" + image_names[i])\n",
    "        img.save(destination_path + \"/\" + str(image_labels[i]) + \"/\" + image_names[i])\n",
    "        \n",
    "\n",
    "# generate_label_folders(image_dir, X_train, y_train, training_path)\n",
    "# generate_label_folders(image_dir, X_test, y_test, validation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading\n",
    "Because the dataset is so large, we cant just load it into our memory. Instead we generate batches of images. These images are then altered a little bit to create higher variance between images and artificially increase the size of our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=normalize,\n",
    "        shear_range=2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range = 2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=normalize)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        training_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_image_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15,15))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    # convert to unsigned integers for plotting\n",
    "    image = next(train_generator)[0][0]\n",
    "    # changing size from (1, 200, 200, 3) to (200, 200, 3) for plotting the image\n",
    "    image = np.squeeze(image) * 0.5 + 0.5\n",
    "    # plot raw pixel data\n",
    "    ax[i].imshow(image)\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, steps_per_epoch=150, epochs=3, validation_steps=20, workers=7, checkpoint_loc=\"\"):\n",
    "    \"\"\"\n",
    "    Trains a given model\n",
    "\n",
    "    :steps_per_epoch: Amount of batches uploaded per epoch. Cant be higher than +- 200\n",
    "    :epochs: Amount of times the model trains on the data\n",
    "    :validation_steps: Amount of batches used for validation. Cant be higher than +- 50\n",
    "    :workers: Amount of processes used to load the data\n",
    "    :checkpoint_loc: Place for the model checkpoints to be saved\n",
    "    :return: The trained model and some training data\n",
    "    \"\"\" \n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_loc,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    begin_time = datetime.datetime.now()\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_generator, validation_steps=validation_steps, workers=workers, callbacks=[cp_callback])\n",
    "    print(datetime.datetime.now() - begin_time)\n",
    "    return (model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    #Plots the training data.\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: simple pre-trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MNV2model(n_labels):\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "\n",
    "\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    prediction_layer = tf.keras.layers.Dense(n_labels)\n",
    "\n",
    "    MNV2model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      prediction_layer\n",
    "    ])\n",
    "\n",
    "    base_learning_rate = 0.0001\n",
    "    MNV2model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "#     ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "# manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "    return MNV2model\n",
    "\n",
    "MNV2model = make_MNV2model(n_labels)\n",
    "MNV2model.load_weights(\"../Model_weights/MNV2/\")\n",
    "\n",
    "# MNV2model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNV2model, history_MNV2 = train_model(MNV2model, steps_per_epoch=1, epochs=1, checkpoint_loc=\"../Model_weights/MNV2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_MNV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the test set\n",
    "We also have to predict the real test set and save the results to upload to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test(model):\n",
    "    preds = MNV2model.predict(test_generator)\n",
    "    preds_cls_idx = preds.argmax(axis=-1)\n",
    "    idx_to_cls = {v: k for k, v in train_generator.class_indices.items()}\n",
    "    preds_cls = np.vectorize(idx_to_cls.get)(preds_cls_idx)\n",
    "    filenames_to_cls = list(zip(test_generator.filenames, preds_cls))\n",
    "    \n",
    "    l = []\n",
    "    n = []\n",
    "    for p in filenames_to_cls:\n",
    "        n.append(p[0].split(\"\\\\\")[-1])\n",
    "        l.append(p[1])\n",
    "    return pd.DataFrame(list(zip(n, l)), columns=['img_name','label'])\n",
    "\n",
    "res = predict_test(MNV2model)\n",
    "res.to_csv(\"sample_submission2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
