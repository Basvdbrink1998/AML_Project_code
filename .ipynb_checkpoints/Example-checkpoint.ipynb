{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import PIL\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../train_set/train_set\"\n",
    "test_image_dir = \"../test_set/test_set\"\n",
    "labels_file = \"../train_labels.csv\"\n",
    "resized_train_dir = \"../resized_train_set\"\n",
    "resized_test_dir = \"../resized_test_set\"\n",
    "img_size = (100, 100)\n",
    "n_batches = 300\n",
    "n_labels = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_2.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_3.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_4.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_5.jpg</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30607</th>\n",
       "      <td>train_30608.jpg</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30608</th>\n",
       "      <td>train_30609.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30609</th>\n",
       "      <td>train_30610.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30610</th>\n",
       "      <td>train_30611.jpg</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30611</th>\n",
       "      <td>train_30612.jpg</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30612 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              img_name  label\n",
       "0          train_1.jpg     21\n",
       "1          train_2.jpg     29\n",
       "2          train_3.jpg     17\n",
       "3          train_4.jpg     21\n",
       "4          train_5.jpg     50\n",
       "...                ...    ...\n",
       "30607  train_30608.jpg     53\n",
       "30608  train_30609.jpg     18\n",
       "30609  train_30610.jpg      6\n",
       "30610  train_30611.jpg     21\n",
       "30611  train_30612.jpg     24\n",
       "\n",
       "[30612 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(labels_file)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_random_images(img_names, n_x=2, n_y=2, seed=0):\n",
    "    f, axs = plt.subplots(n_x, n_y)\n",
    "    sample = img_names.sample(n_x * n_y, random_state=seed)\n",
    "    c = 0\n",
    "    for x in range(n_x):\n",
    "        for y in range(n_y):\n",
    "            img = plt.imread(image_dir + \"/\" + sample.iloc[c])\n",
    "            axs[x, y].imshow(img)\n",
    "            axs[x, y].axis('off')\n",
    "            c += 1\n",
    "\n",
    "plot_random_images(labels[\"img_name\"], 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image size\n",
    "Most machine learning requires that the input is always of the same size. Because our images are not always of the same size. We have to resize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_names, img_dir, new_img_dir):\n",
    "    for img in img_names:\n",
    "        Image.open(img_dir + \"/\" + img).resize(img_size).save(new_img_dir + \"/\" + img)\n",
    "\n",
    "# resize_images(labels[\"img_name\"], image_dir, resized_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels\n",
    "for classification, we need to one hot encode the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(1,n_labels + 1))\n",
    "\n",
    "def encode(labels):\n",
    "    z = np.zeros((len(labels), n_labels))\n",
    "    for i, label in enumerate(labels):\n",
    "        z[i, label-1] = 1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split\n",
    "To test our models locally, we must split our data into a train and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(labels[\"img_name\"].to_numpy(), labels[\"label\"].to_numpy(), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data set is very large, it is a good idea to split the sets into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batches = np.array_split(X_train, n_batches)\n",
    "X_test_batches = np.array_split(X_test, n_batches)\n",
    "y_train_batches = np.array_split(y_train, n_batches)\n",
    "y_test_batches = np.array_split(y_test, n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 100, 100, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_images(img_names, img_dir):\n",
    "    res = np.zeros((len(img_names), img_size[0], img_size[1], 3))\n",
    "    for i, img in enumerate(img_names):\n",
    "        res[i] = plt.imread(img_dir + \"/\" + img)\n",
    "    return res\n",
    "\n",
    "load_images(X_train_batches[0], resized_train_dir).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 100, 100, 50)      1400      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 100, 100, 75)      33825     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 50, 50, 75)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 50, 75)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 50, 50, 125)       84500     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 25, 25, 125)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 25, 25, 125)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 78125)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 500)               39063000  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 250)               125250    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 80)                20080     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,328,055\n",
      "Trainable params: 39,328,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "\n",
    "# convolutional layer\n",
    "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#output layer\n",
    "model.add(layers.Dense(80))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 704ms/step - loss: 1.3936 - accuracy: 0.6812 - val_loss: 6.9339 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 731ms/step - loss: 1.8231 - accuracy: 0.6957 - val_loss: 7.0969 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 698ms/step - loss: 1.5697 - accuracy: 0.6377 - val_loss: 7.2724 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 690ms/step - loss: 1.5601 - accuracy: 0.6377 - val_loss: 7.3571 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 1.2791 - accuracy: 0.7101 - val_loss: 7.6325 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 1.3665 - accuracy: 0.7536 - val_loss: 7.9342 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 1.6964 - accuracy: 0.6812 - val_loss: 8.0020 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 1.2784 - accuracy: 0.7391 - val_loss: 7.6951 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 1.4720 - accuracy: 0.6812 - val_loss: 7.3822 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 1.1584 - accuracy: 0.7101 - val_loss: 7.1854 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 1.3011 - accuracy: 0.6812 - val_loss: 7.1307 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 1.3480 - accuracy: 0.7101 - val_loss: 7.0495 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 1.1557 - accuracy: 0.7391 - val_loss: 6.8972 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 0.9485 - accuracy: 0.7681 - val_loss: 6.9303 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 1.2842 - accuracy: 0.7101 - val_loss: 7.0099 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 0.9110 - accuracy: 0.7536 - val_loss: 7.0207 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 1.2035 - accuracy: 0.7391 - val_loss: 7.0631 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 1.4627 - accuracy: 0.6087 - val_loss: 7.1312 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 1.1335 - accuracy: 0.7246 - val_loss: 7.2081 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 1.2255 - accuracy: 0.6522 - val_loss: 7.3131 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 12.3414 - accuracy: 0.0435 - val_loss: 6.6948 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 7.4488 - accuracy: 0.0290 - val_loss: 5.8528 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 7.0295 - accuracy: 0.0145 - val_loss: 5.3582 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 6.2379 - accuracy: 0.0000e+00 - val_loss: 4.9846 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 5.8408 - accuracy: 0.0000e+00 - val_loss: 4.7351 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.6076 - accuracy: 0.0000e+00 - val_loss: 4.6670 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.5949 - accuracy: 0.0290 - val_loss: 4.6302 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.6993 - accuracy: 0.0000e+00 - val_loss: 4.5600 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.6944 - accuracy: 0.0145 - val_loss: 4.5613 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.4384 - accuracy: 0.0435 - val_loss: 4.5650 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.5354 - accuracy: 0.0290 - val_loss: 4.5462 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 711ms/step - loss: 4.4622 - accuracy: 0.0145 - val_loss: 4.5119 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.4491 - accuracy: 0.0290 - val_loss: 4.4744 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.4397 - accuracy: 0.0290 - val_loss: 4.4478 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4715 - accuracy: 0.0290 - val_loss: 4.4723 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4322 - accuracy: 0.0290 - val_loss: 4.4954 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.4052 - accuracy: 0.0000e+00 - val_loss: 4.4946 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3910 - accuracy: 0.0435 - val_loss: 4.4640 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.3762 - accuracy: 0.0145 - val_loss: 4.4339 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.4480 - accuracy: 0.0000e+00 - val_loss: 4.4220 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3880 - accuracy: 0.0290 - val_loss: 4.4451 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3384 - accuracy: 0.0145 - val_loss: 4.4881 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 4.3518 - accuracy: 0.0435 - val_loss: 4.5286 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3746 - accuracy: 0.0290 - val_loss: 4.5302 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4116 - accuracy: 0.0145 - val_loss: 4.5013 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4614 - accuracy: 0.0145 - val_loss: 4.4578 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 676ms/step - loss: 4.3404 - accuracy: 0.0000e+00 - val_loss: 4.4412 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 650ms/step - loss: 4.4545 - accuracy: 0.0145 - val_loss: 4.4413 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 649ms/step - loss: 4.4510 - accuracy: 0.0290 - val_loss: 4.4228 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 624ms/step - loss: 4.3806 - accuracy: 0.0145 - val_loss: 4.4250 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 4.4294 - accuracy: 0.0000e+00 - val_loss: 4.4469 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.3762 - accuracy: 0.0000e+00 - val_loss: 4.4569 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.5108 - accuracy: 0.0145 - val_loss: 4.4810 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.4336 - accuracy: 0.0145 - val_loss: 4.4747 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3704 - accuracy: 0.0145 - val_loss: 4.4270 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.4111 - accuracy: 0.0000e+00 - val_loss: 4.4178 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.5044 - accuracy: 0.0145 - val_loss: 4.4187 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.3582 - accuracy: 0.0435 - val_loss: 4.4277 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.4196 - accuracy: 0.0290 - val_loss: 4.4163 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.4318 - accuracy: 0.0290 - val_loss: 4.4139 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4057 - accuracy: 0.0290 - val_loss: 4.4178 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3409 - accuracy: 0.0000e+00 - val_loss: 4.4255 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3761 - accuracy: 0.0145 - val_loss: 4.4423 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3702 - accuracy: 0.0000e+00 - val_loss: 4.4471 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3922 - accuracy: 0.0000e+00 - val_loss: 4.4437 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.4494 - accuracy: 0.0145 - val_loss: 4.4233 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.3713 - accuracy: 0.0145 - val_loss: 4.3978 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.4012 - accuracy: 0.0145 - val_loss: 4.3995 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.5691 - accuracy: 0.0145 - val_loss: 4.4019 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.3929 - accuracy: 0.0145 - val_loss: 4.4412 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.2816 - accuracy: 0.0290 - val_loss: 4.4469 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3569 - accuracy: 0.0145 - val_loss: 4.4553 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.4027 - accuracy: 0.0145 - val_loss: 4.4592 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3619 - accuracy: 0.0000e+00 - val_loss: 4.4771 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.3724 - accuracy: 0.0290 - val_loss: 4.4844 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4622 - accuracy: 0.0000e+00 - val_loss: 4.4862 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.4005 - accuracy: 0.0435 - val_loss: 4.4873 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 582ms/step - loss: 4.4352 - accuracy: 0.0435 - val_loss: 4.4911 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 678ms/step - loss: 4.3698 - accuracy: 0.0000e+00 - val_loss: 4.4880 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4066 - accuracy: 0.0000e+00 - val_loss: 4.4804 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.4341 - accuracy: 0.0145 - val_loss: 4.4675 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3595 - accuracy: 0.0000e+00 - val_loss: 4.4469 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3567 - accuracy: 0.0145 - val_loss: 4.4411 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.4130 - accuracy: 0.0000e+00 - val_loss: 4.4445 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.4041 - accuracy: 0.0145 - val_loss: 4.4439 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.4663 - accuracy: 0.0000e+00 - val_loss: 4.4387 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.3744 - accuracy: 0.0000e+00 - val_loss: 4.4289 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.3322 - accuracy: 0.0435 - val_loss: 4.4076 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3622 - accuracy: 0.0145 - val_loss: 4.3937 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3755 - accuracy: 0.0000e+00 - val_loss: 4.3784 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3616 - accuracy: 0.0435 - val_loss: 4.3493 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.4129 - accuracy: 0.0000e+00 - val_loss: 4.3445 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.3786 - accuracy: 0.0145 - val_loss: 4.3511 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.3937 - accuracy: 0.0000e+00 - val_loss: 4.3714 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4321 - accuracy: 0.0000e+00 - val_loss: 4.3879 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4218 - accuracy: 0.0000e+00 - val_loss: 4.3870 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4473 - accuracy: 0.0435 - val_loss: 4.4033 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4749 - accuracy: 0.0000e+00 - val_loss: 4.4125 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.4192 - accuracy: 0.0290 - val_loss: 4.4192 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3550 - accuracy: 0.0145 - val_loss: 4.4223 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3613 - accuracy: 0.0145 - val_loss: 4.4171 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3807 - accuracy: 0.0435 - val_loss: 4.4113 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3992 - accuracy: 0.0145 - val_loss: 4.4074 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3804 - accuracy: 0.0290 - val_loss: 4.4099 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4100 - accuracy: 0.0290 - val_loss: 4.4135 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.3748 - accuracy: 0.0000e+00 - val_loss: 4.4172 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.4486 - accuracy: 0.0145 - val_loss: 4.4109 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3797 - accuracy: 0.0145 - val_loss: 4.4070 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 4.4296 - accuracy: 0.0000e+00 - val_loss: 4.4045 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 4.3436 - accuracy: 0.0290 - val_loss: 4.4066 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3199 - accuracy: 0.0000e+00 - val_loss: 4.4117 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.4107 - accuracy: 0.0000e+00 - val_loss: 4.4137 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.4122 - accuracy: 0.0000e+00 - val_loss: 4.4132 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.4851 - accuracy: 0.0000e+00 - val_loss: 4.4103 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.4193 - accuracy: 0.0147 - val_loss: 4.4041 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3946 - accuracy: 0.0147 - val_loss: 4.4012 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 625ms/step - loss: 4.4155 - accuracy: 0.0000e+00 - val_loss: 4.3964 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 625ms/step - loss: 4.4034 - accuracy: 0.0000e+00 - val_loss: 4.3882 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.3937 - accuracy: 0.0147 - val_loss: 4.3875 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.3575 - accuracy: 0.0294 - val_loss: 4.3968 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 580ms/step - loss: 4.4154 - accuracy: 0.0588 - val_loss: 4.3940 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 584ms/step - loss: 4.3772 - accuracy: 0.0000e+00 - val_loss: 4.3984 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 4.3626 - accuracy: 0.0294 - val_loss: 4.4080 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 682ms/step - loss: 4.3757 - accuracy: 0.0147 - val_loss: 4.4156 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.3218 - accuracy: 0.0147 - val_loss: 4.4164 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3523 - accuracy: 0.0294 - val_loss: 4.4149 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4455 - accuracy: 0.0000e+00 - val_loss: 4.4103 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3746 - accuracy: 0.0147 - val_loss: 4.4069 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.3313 - accuracy: 0.0147 - val_loss: 4.4077 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3735 - accuracy: 0.0147 - val_loss: 4.4104 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3719 - accuracy: 0.0294 - val_loss: 4.4069 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.4279 - accuracy: 0.0000e+00 - val_loss: 4.4061 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 634ms/step - loss: 4.3754 - accuracy: 0.0000e+00 - val_loss: 4.4011 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3493 - accuracy: 0.0147 - val_loss: 4.3917 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3476 - accuracy: 0.0147 - val_loss: 4.3851 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4178 - accuracy: 0.0000e+00 - val_loss: 4.3831 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3303 - accuracy: 0.0000e+00 - val_loss: 4.3830 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3559 - accuracy: 0.0294 - val_loss: 4.3834 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.3852 - accuracy: 0.0294 - val_loss: 4.3817 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.4629 - accuracy: 0.0000e+00 - val_loss: 4.3783 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3687 - accuracy: 0.0000e+00 - val_loss: 4.3687 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.4557 - accuracy: 0.0147 - val_loss: 4.3720 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.4130 - accuracy: 0.0147 - val_loss: 4.3733 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3979 - accuracy: 0.0000e+00 - val_loss: 4.3717 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.3620 - accuracy: 0.0147 - val_loss: 4.3761 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3977 - accuracy: 0.0147 - val_loss: 4.3821 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.4532 - accuracy: 0.0000e+00 - val_loss: 4.3890 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3962 - accuracy: 0.0147 - val_loss: 4.3933 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3730 - accuracy: 0.0147 - val_loss: 4.3999 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4271 - accuracy: 0.0000e+00 - val_loss: 4.4078 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.4061 - accuracy: 0.0294 - val_loss: 4.4112 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3365 - accuracy: 0.0000e+00 - val_loss: 4.4079 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3751 - accuracy: 0.0147 - val_loss: 4.3899 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3854 - accuracy: 0.0000e+00 - val_loss: 4.3747 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3506 - accuracy: 0.0294 - val_loss: 4.3702 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3379 - accuracy: 0.0147 - val_loss: 4.3724 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3608 - accuracy: 0.0000e+00 - val_loss: 4.3836 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.4557 - accuracy: 0.0147 - val_loss: 4.3939 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3452 - accuracy: 0.0000e+00 - val_loss: 4.3881 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3686 - accuracy: 0.0000e+00 - val_loss: 4.3746 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.4111 - accuracy: 0.0000e+00 - val_loss: 4.3658 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3938 - accuracy: 0.0000e+00 - val_loss: 4.3605 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.4466 - accuracy: 0.0000e+00 - val_loss: 4.3634 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3705 - accuracy: 0.0147 - val_loss: 4.3671 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3795 - accuracy: 0.0000e+00 - val_loss: 4.3734 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3683 - accuracy: 0.0000e+00 - val_loss: 4.3697 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.3688 - accuracy: 0.0000e+00 - val_loss: 4.3658 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.4165 - accuracy: 0.0000e+00 - val_loss: 4.3680 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4169 - accuracy: 0.0294 - val_loss: 4.3677 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 4.4268 - accuracy: 0.0147 - val_loss: 4.3690 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 4.3163 - accuracy: 0.0000e+00 - val_loss: 4.3839 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 4.4111 - accuracy: 0.0147 - val_loss: 4.3931 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.3975 - accuracy: 0.0147 - val_loss: 4.3987 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3710 - accuracy: 0.0147 - val_loss: 4.3998 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.4064 - accuracy: 0.0147 - val_loss: 4.3982 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.3911 - accuracy: 0.0294 - val_loss: 4.3957 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 4.3820 - accuracy: 0.0000e+00 - val_loss: 4.3919 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.3956 - accuracy: 0.0147 - val_loss: 4.3877 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3885 - accuracy: 0.0147 - val_loss: 4.3831 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 4.3507 - accuracy: 0.0294 - val_loss: 4.3827 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3405 - accuracy: 0.0000e+00 - val_loss: 4.3830 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3966 - accuracy: 0.0000e+00 - val_loss: 4.3829 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4302 - accuracy: 0.0294 - val_loss: 4.3762 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.3275 - accuracy: 0.0294 - val_loss: 4.3712 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4438 - accuracy: 0.0000e+00 - val_loss: 4.3788 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3883 - accuracy: 0.0147 - val_loss: 4.3810 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.4292 - accuracy: 0.0147 - val_loss: 4.3816 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3932 - accuracy: 0.0000e+00 - val_loss: 4.3771 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.7559 - accuracy: 0.0147 - val_loss: 4.3744 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3590 - accuracy: 0.0000e+00 - val_loss: 4.3756 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4102 - accuracy: 0.0294 - val_loss: 4.3794 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.3333 - accuracy: 0.0147 - val_loss: 4.3799 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.4045 - accuracy: 0.0147 - val_loss: 4.3806 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 651ms/step - loss: 4.3856 - accuracy: 0.0000e+00 - val_loss: 4.3791 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 4.3754 - accuracy: 0.0147 - val_loss: 4.3758 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 629ms/step - loss: 4.3912 - accuracy: 0.0000e+00 - val_loss: 4.3721 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3854 - accuracy: 0.0147 - val_loss: 4.3703 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3706 - accuracy: 0.0147 - val_loss: 4.3669 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3784 - accuracy: 0.0147 - val_loss: 4.3649 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3678 - accuracy: 0.0000e+00 - val_loss: 4.3635 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.3636 - accuracy: 0.0435 - val_loss: 4.3562 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.2655 - accuracy: 0.0435 - val_loss: 4.3579 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.3141 - accuracy: 0.0145 - val_loss: 4.3656 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.2349 - accuracy: 0.1014 - val_loss: 4.3712 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.1902 - accuracy: 0.1014 - val_loss: 4.3796 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.1641 - accuracy: 0.1159 - val_loss: 4.3849 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 3.9931 - accuracy: 0.1884 - val_loss: 4.3884 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 3.9336 - accuracy: 0.1739 - val_loss: 4.3925 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 3.9308 - accuracy: 0.2029 - val_loss: 4.3982 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 3.5866 - accuracy: 0.2464 - val_loss: 4.3897 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 3.3517 - accuracy: 0.2899 - val_loss: 4.4096 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 3.2007 - accuracy: 0.3333 - val_loss: 4.4937 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 3.3502 - accuracy: 0.2754 - val_loss: 4.6944 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 2.3501 - accuracy: 0.5507 - val_loss: 4.8073 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 3.5925 - accuracy: 0.3768 - val_loss: 4.9512 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 680ms/step - loss: 2.4483 - accuracy: 0.4493 - val_loss: 4.8878 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 2.4457 - accuracy: 0.4783 - val_loss: 5.0203 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 2.4740 - accuracy: 0.4348 - val_loss: 5.3559 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 1.7724 - accuracy: 0.5797 - val_loss: 5.6960 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 2.2303 - accuracy: 0.5507 - val_loss: 5.6735 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 8.0913 - accuracy: 0.0580 - val_loss: 4.9592 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 5.2473 - accuracy: 0.0290 - val_loss: 4.6771 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.9729 - accuracy: 0.0580 - val_loss: 4.5079 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.9058 - accuracy: 0.0580 - val_loss: 4.4040 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.6851 - accuracy: 0.0000e+00 - val_loss: 4.4043 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.4442 - accuracy: 0.0725 - val_loss: 4.3947 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.2501 - accuracy: 0.0435 - val_loss: 4.3897 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4820 - accuracy: 0.0580 - val_loss: 4.3923 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.2806 - accuracy: 0.0580 - val_loss: 4.3872 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3869 - accuracy: 0.0435 - val_loss: 4.3878 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 627ms/step - loss: 4.4273 - accuracy: 0.0000e+00 - val_loss: 4.3881 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.3464 - accuracy: 0.0435 - val_loss: 4.3885 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.3229 - accuracy: 0.0290 - val_loss: 4.3884 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.3936 - accuracy: 0.0145 - val_loss: 4.3873 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.3540 - accuracy: 0.0290 - val_loss: 4.3784 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3964 - accuracy: 0.0000e+00 - val_loss: 4.3745 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.3970 - accuracy: 0.0290 - val_loss: 4.3759 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3174 - accuracy: 0.0145 - val_loss: 4.3735 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3387 - accuracy: 0.0290 - val_loss: 4.3791 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.3402 - accuracy: 0.0145 - val_loss: 4.3799 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3668 - accuracy: 0.0000e+00 - val_loss: 4.3798 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.3823 - accuracy: 0.0145 - val_loss: 4.3821 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.2891 - accuracy: 0.0725 - val_loss: 4.3851 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3364 - accuracy: 0.0145 - val_loss: 4.3882 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.4069 - accuracy: 0.0290 - val_loss: 4.3912 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 603ms/step - loss: 4.4659 - accuracy: 0.0000e+00 - val_loss: 4.3895 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3648 - accuracy: 0.0145 - val_loss: 4.3914 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3605 - accuracy: 0.0290 - val_loss: 4.3932 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.3456 - accuracy: 0.0290 - val_loss: 4.3945 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3078 - accuracy: 0.0290 - val_loss: 4.3958 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3885 - accuracy: 0.0290 - val_loss: 4.4024 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3868 - accuracy: 0.0290 - val_loss: 4.4094 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.4136 - accuracy: 0.0000e+00 - val_loss: 4.4119 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.5075 - accuracy: 0.0145 - val_loss: 4.3981 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3948 - accuracy: 0.0145 - val_loss: 4.3918 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.4874 - accuracy: 0.0145 - val_loss: 4.3908 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3891 - accuracy: 0.0290 - val_loss: 4.3892 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.3294 - accuracy: 0.0000e+00 - val_loss: 4.3876 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3445 - accuracy: 0.0435 - val_loss: 4.3885 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.4042 - accuracy: 0.0435 - val_loss: 4.3863 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.3497 - accuracy: 0.0145 - val_loss: 4.3859 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.3395 - accuracy: 0.0290 - val_loss: 4.3859 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 682ms/step - loss: 4.3827 - accuracy: 0.0145 - val_loss: 4.3864 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4295 - accuracy: 0.0145 - val_loss: 4.3819 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3228 - accuracy: 0.0435 - val_loss: 4.3825 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.4240 - accuracy: 0.0290 - val_loss: 4.3841 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4249 - accuracy: 0.0000e+00 - val_loss: 4.3811 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3731 - accuracy: 0.0000e+00 - val_loss: 4.3804 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4042 - accuracy: 0.0145 - val_loss: 4.3758 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3482 - accuracy: 0.0000e+00 - val_loss: 4.3743 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.2915 - accuracy: 0.0000e+00 - val_loss: 4.3711 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3485 - accuracy: 0.0145 - val_loss: 4.3696 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3546 - accuracy: 0.0145 - val_loss: 4.3772 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.2644 - accuracy: 0.0145 - val_loss: 4.3821 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.3748 - accuracy: 0.0290 - val_loss: 4.3839 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3866 - accuracy: 0.0000e+00 - val_loss: 4.3847 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4386 - accuracy: 0.0145 - val_loss: 4.3845 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.3451 - accuracy: 0.0145 - val_loss: 4.3826 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3852 - accuracy: 0.0145 - val_loss: 4.3801 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3824 - accuracy: 0.0145 - val_loss: 4.3762 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3094 - accuracy: 0.0290 - val_loss: 4.3653 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3689 - accuracy: 0.0000e+00 - val_loss: 4.3654 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3375 - accuracy: 0.0145 - val_loss: 4.3687 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.3793 - accuracy: 0.0000e+00 - val_loss: 4.3757 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3657 - accuracy: 0.0000e+00 - val_loss: 4.3806 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 617ms/step - loss: 4.3674 - accuracy: 0.0290 - val_loss: 4.3827 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.4132 - accuracy: 0.0000e+00 - val_loss: 4.3837 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3539 - accuracy: 0.0290 - val_loss: 4.3825 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.3230 - accuracy: 0.0290 - val_loss: 4.3811 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3885 - accuracy: 0.0000e+00 - val_loss: 4.3808 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.3429 - accuracy: 0.0145 - val_loss: 4.3761 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 4.3712 - accuracy: 0.0000e+00 - val_loss: 4.3678 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.3549 - accuracy: 0.0580 - val_loss: 4.3571 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3728 - accuracy: 0.0145 - val_loss: 4.3513 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3858 - accuracy: 0.0000e+00 - val_loss: 4.3514 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3326 - accuracy: 0.0580 - val_loss: 4.3568 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3862 - accuracy: 0.0580 - val_loss: 4.3611 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3627 - accuracy: 0.0145 - val_loss: 4.3717 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.4089 - accuracy: 0.0000e+00 - val_loss: 4.3850 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 622ms/step - loss: 4.2844 - accuracy: 0.0580 - val_loss: 4.3904 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3093 - accuracy: 0.0290 - val_loss: 4.3894 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 623ms/step - loss: 4.3639 - accuracy: 0.0000e+00 - val_loss: 4.3872 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3583 - accuracy: 0.0000e+00 - val_loss: 4.3818 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.3621 - accuracy: 0.0145 - val_loss: 4.3776 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3581 - accuracy: 0.0000e+00 - val_loss: 4.3737 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3482 - accuracy: 0.0000e+00 - val_loss: 4.3672 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4108 - accuracy: 0.0145 - val_loss: 4.3518 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 706ms/step - loss: 4.4372 - accuracy: 0.0145 - val_loss: 4.3515 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3786 - accuracy: 0.0000e+00 - val_loss: 4.3592 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3365 - accuracy: 0.0145 - val_loss: 4.3580 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.3844 - accuracy: 0.0000e+00 - val_loss: 4.3537 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3833 - accuracy: 0.0000e+00 - val_loss: 4.3627 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3554 - accuracy: 0.0441 - val_loss: 4.3644 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.4007 - accuracy: 0.0147 - val_loss: 4.3622 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.3682 - accuracy: 0.0000e+00 - val_loss: 4.3640 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4068 - accuracy: 0.0294 - val_loss: 4.3662 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3418 - accuracy: 0.0000e+00 - val_loss: 4.3668 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3743 - accuracy: 0.0441 - val_loss: 4.3679 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3560 - accuracy: 0.0000e+00 - val_loss: 4.3687 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3531 - accuracy: 0.0441 - val_loss: 4.3674 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3489 - accuracy: 0.0147 - val_loss: 4.3662 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.3640 - accuracy: 0.0294 - val_loss: 4.3709 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3658 - accuracy: 0.0147 - val_loss: 4.3763 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.2978 - accuracy: 0.0294 - val_loss: 4.3806 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.5009 - accuracy: 0.0000e+00 - val_loss: 4.3841 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3473 - accuracy: 0.0147 - val_loss: 4.3863 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4143 - accuracy: 0.0000e+00 - val_loss: 4.3866 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3468 - accuracy: 0.0147 - val_loss: 4.3865 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3409 - accuracy: 0.0294 - val_loss: 4.3852 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.3140 - accuracy: 0.0147 - val_loss: 4.3836 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.3671 - accuracy: 0.0147 - val_loss: 4.3795 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3541 - accuracy: 0.0294 - val_loss: 4.3818 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3294 - accuracy: 0.0000e+00 - val_loss: 4.3812 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3671 - accuracy: 0.0147 - val_loss: 4.3840 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3072 - accuracy: 0.0441 - val_loss: 4.3871 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 581ms/step - loss: 4.3097 - accuracy: 0.0000e+00 - val_loss: 4.3871 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.2471 - accuracy: 0.0441 - val_loss: 4.3853 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.3651 - accuracy: 0.0147 - val_loss: 4.3804 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3391 - accuracy: 0.0441 - val_loss: 4.3747 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.4043 - accuracy: 0.0147 - val_loss: 4.3712 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 4.4007 - accuracy: 0.0147 - val_loss: 4.3966 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 624ms/step - loss: 4.4020 - accuracy: 0.0000e+00 - val_loss: 4.3846 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3263 - accuracy: 0.0294 - val_loss: 4.3792 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3449 - accuracy: 0.0441 - val_loss: 4.3783 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3029 - accuracy: 0.0147 - val_loss: 4.3778 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3758 - accuracy: 0.0000e+00 - val_loss: 4.3787 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3670 - accuracy: 0.0147 - val_loss: 4.3875 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4108 - accuracy: 0.0000e+00 - val_loss: 4.3904 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3271 - accuracy: 0.0147 - val_loss: 4.3895 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3866 - accuracy: 0.0147 - val_loss: 4.3849 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3933 - accuracy: 0.0147 - val_loss: 4.3835 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.2763 - accuracy: 0.0294 - val_loss: 4.3813 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.3691 - accuracy: 0.0294 - val_loss: 4.3812 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 578ms/step - loss: 4.3641 - accuracy: 0.0147 - val_loss: 4.3802 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 679ms/step - loss: 4.3602 - accuracy: 0.0147 - val_loss: 4.3780 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3630 - accuracy: 0.0147 - val_loss: 4.3768 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 584ms/step - loss: 4.3437 - accuracy: 0.0147 - val_loss: 4.3755 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.4101 - accuracy: 0.0000e+00 - val_loss: 4.3746 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.2994 - accuracy: 0.0441 - val_loss: 4.3758 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3715 - accuracy: 0.0147 - val_loss: 4.3777 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3977 - accuracy: 0.0294 - val_loss: 4.3789 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.3597 - accuracy: 0.0147 - val_loss: 4.3795 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.4267 - accuracy: 0.0000e+00 - val_loss: 4.3789 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.3848 - accuracy: 0.0000e+00 - val_loss: 4.3755 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.3388 - accuracy: 0.0000e+00 - val_loss: 4.3755 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3942 - accuracy: 0.0147 - val_loss: 4.3736 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3378 - accuracy: 0.0000e+00 - val_loss: 4.3690 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4163 - accuracy: 0.0147 - val_loss: 4.3679 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3649 - accuracy: 0.0147 - val_loss: 4.3674 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4684 - accuracy: 0.0000e+00 - val_loss: 4.3698 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.2960 - accuracy: 0.0294 - val_loss: 4.3680 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.4121 - accuracy: 0.0000e+00 - val_loss: 4.3654 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3625 - accuracy: 0.0294 - val_loss: 4.3619 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3580 - accuracy: 0.0441 - val_loss: 4.3611 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3709 - accuracy: 0.0441 - val_loss: 4.3625 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3710 - accuracy: 0.0000e+00 - val_loss: 4.3644 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3450 - accuracy: 0.0294 - val_loss: 4.3641 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3760 - accuracy: 0.0147 - val_loss: 4.3628 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3378 - accuracy: 0.0441 - val_loss: 4.3617 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3702 - accuracy: 0.0000e+00 - val_loss: 4.3614 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 624ms/step - loss: 4.3462 - accuracy: 0.0294 - val_loss: 4.3626 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3337 - accuracy: 0.0000e+00 - val_loss: 4.3684 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3912 - accuracy: 0.0294 - val_loss: 4.3722 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.3328 - accuracy: 0.0000e+00 - val_loss: 4.3732 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3220 - accuracy: 0.0294 - val_loss: 4.3701 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3975 - accuracy: 0.0000e+00 - val_loss: 4.3682 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.4080 - accuracy: 0.0147 - val_loss: 4.3670 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.4009 - accuracy: 0.0294 - val_loss: 4.3694 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3644 - accuracy: 0.0441 - val_loss: 4.3714 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3544 - accuracy: 0.0294 - val_loss: 4.3716 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3526 - accuracy: 0.0294 - val_loss: 4.3738 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.3519 - accuracy: 0.0000e+00 - val_loss: 4.3769 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.3532 - accuracy: 0.0294 - val_loss: 4.3791 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.3865 - accuracy: 0.0000e+00 - val_loss: 4.3811 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.3352 - accuracy: 0.0000e+00 - val_loss: 4.3818 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 4.4177 - accuracy: 0.0000e+00 - val_loss: 4.3904 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.4296 - accuracy: 0.0294 - val_loss: 4.3880 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.4041 - accuracy: 0.0294 - val_loss: 4.3901 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3621 - accuracy: 0.0147 - val_loss: 4.3916 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.3809 - accuracy: 0.0000e+00 - val_loss: 4.3927 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3067 - accuracy: 0.0435 - val_loss: 4.3930 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.1628 - accuracy: 0.0725 - val_loss: 4.3922 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.2670 - accuracy: 0.0725 - val_loss: 4.3885 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.2378 - accuracy: 0.0725 - val_loss: 4.3865 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.1951 - accuracy: 0.0725 - val_loss: 4.3886 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 625ms/step - loss: 4.0387 - accuracy: 0.1159 - val_loss: 4.3964 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 3.9549 - accuracy: 0.1159 - val_loss: 4.4079 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 3.7502 - accuracy: 0.2174 - val_loss: 4.4289 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 3.7787 - accuracy: 0.2029 - val_loss: 4.4668 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 3.2198 - accuracy: 0.2899 - val_loss: 4.5146 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 3.0957 - accuracy: 0.2609 - val_loss: 4.6559 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 3.5593 - accuracy: 0.2319 - val_loss: 4.6861 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 2.9325 - accuracy: 0.3188 - val_loss: 4.6255 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 2.6980 - accuracy: 0.3913 - val_loss: 4.5352 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 2.7309 - accuracy: 0.4348 - val_loss: 4.5089 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 2.6816 - accuracy: 0.5072 - val_loss: 4.5148 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 2.3058 - accuracy: 0.5217 - val_loss: 4.5481 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 2.1928 - accuracy: 0.4638 - val_loss: 4.6214 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 1.8316 - accuracy: 0.5362 - val_loss: 4.7422 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 1.8650 - accuracy: 0.5652 - val_loss: 4.9434 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.8161 - accuracy: 0.1594 - val_loss: 4.9118 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.7611 - accuracy: 0.1014 - val_loss: 4.4952 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.7853 - accuracy: 0.0435 - val_loss: 4.4176 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 5.0409 - accuracy: 0.0000e+00 - val_loss: 4.3790 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.6492 - accuracy: 0.0145 - val_loss: 4.3993 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 628ms/step - loss: 4.5414 - accuracy: 0.0290 - val_loss: 4.3727 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 642ms/step - loss: 4.3950 - accuracy: 0.0290 - val_loss: 4.3891 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 632ms/step - loss: 4.3547 - accuracy: 0.0145 - val_loss: 4.4367 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.5087 - accuracy: 0.0290 - val_loss: 4.3974 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.2727 - accuracy: 0.0580 - val_loss: 4.3972 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3057 - accuracy: 0.0145 - val_loss: 4.4400 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3844 - accuracy: 0.0290 - val_loss: 4.4011 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.4440 - accuracy: 0.0000e+00 - val_loss: 4.4073 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 585ms/step - loss: 4.4772 - accuracy: 0.0145 - val_loss: 4.4157 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.4196 - accuracy: 0.0000e+00 - val_loss: 4.4286 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4631 - accuracy: 0.0145 - val_loss: 4.4120 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.4311 - accuracy: 0.0290 - val_loss: 4.4156 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.2367 - accuracy: 0.0580 - val_loss: 4.4168 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.3645 - accuracy: 0.0435 - val_loss: 4.4171 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3907 - accuracy: 0.0145 - val_loss: 4.4130 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.2483 - accuracy: 0.0870 - val_loss: 4.4080 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.4201 - accuracy: 0.0145 - val_loss: 4.4078 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.2835 - accuracy: 0.0435 - val_loss: 4.4089 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.2734 - accuracy: 0.0290 - val_loss: 4.4104 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 4.2598 - accuracy: 0.0435 - val_loss: 4.4092 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.3600 - accuracy: 0.0145 - val_loss: 4.4062 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3837 - accuracy: 0.0145 - val_loss: 4.4045 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3901 - accuracy: 0.0000e+00 - val_loss: 4.3999 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3761 - accuracy: 0.0145 - val_loss: 4.4064 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3386 - accuracy: 0.0580 - val_loss: 4.4081 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3336 - accuracy: 0.0290 - val_loss: 4.4112 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3475 - accuracy: 0.0145 - val_loss: 4.4097 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3727 - accuracy: 0.0290 - val_loss: 4.4073 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 596ms/step - loss: 4.3751 - accuracy: 0.0000e+00 - val_loss: 4.4069 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 621ms/step - loss: 4.3978 - accuracy: 0.0290 - val_loss: 4.4051 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 624ms/step - loss: 4.3512 - accuracy: 0.0000e+00 - val_loss: 4.3959 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3821 - accuracy: 0.0000e+00 - val_loss: 4.3909 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 616ms/step - loss: 4.2878 - accuracy: 0.0145 - val_loss: 4.3971 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3114 - accuracy: 0.0290 - val_loss: 4.4027 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.3860 - accuracy: 0.0145 - val_loss: 4.4016 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3572 - accuracy: 0.0000e+00 - val_loss: 4.3989 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3862 - accuracy: 0.0000e+00 - val_loss: 4.3964 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3272 - accuracy: 0.0145 - val_loss: 4.3957 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3871 - accuracy: 0.0435 - val_loss: 4.3946 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 627ms/step - loss: 4.2530 - accuracy: 0.0290 - val_loss: 4.3922 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3562 - accuracy: 0.0145 - val_loss: 4.3925 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3786 - accuracy: 0.0000e+00 - val_loss: 4.3899 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3646 - accuracy: 0.0000e+00 - val_loss: 4.3869 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.3238 - accuracy: 0.0580 - val_loss: 4.3855 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3479 - accuracy: 0.0145 - val_loss: 4.3824 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3198 - accuracy: 0.0290 - val_loss: 4.3838 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3433 - accuracy: 0.0000e+00 - val_loss: 4.3945 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3489 - accuracy: 0.0435 - val_loss: 4.3987 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3034 - accuracy: 0.0435 - val_loss: 4.3835 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3727 - accuracy: 0.0145 - val_loss: 4.3758 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3751 - accuracy: 0.0000e+00 - val_loss: 4.3755 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.2797 - accuracy: 0.0435 - val_loss: 4.3731 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3377 - accuracy: 0.0290 - val_loss: 4.3734 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3973 - accuracy: 0.0145 - val_loss: 4.3724 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.4118 - accuracy: 0.0145 - val_loss: 4.3713 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.3850 - accuracy: 0.0000e+00 - val_loss: 4.3702 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3630 - accuracy: 0.0000e+00 - val_loss: 4.3704 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3244 - accuracy: 0.0145 - val_loss: 4.3705 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 614ms/step - loss: 4.3597 - accuracy: 0.0000e+00 - val_loss: 4.3688 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.4023 - accuracy: 0.0000e+00 - val_loss: 4.3714 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 619ms/step - loss: 4.4187 - accuracy: 0.0145 - val_loss: 4.3823 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 630ms/step - loss: 4.4081 - accuracy: 0.0000e+00 - val_loss: 4.3794 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 652ms/step - loss: 4.4559 - accuracy: 0.0290 - val_loss: 4.3746 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3675 - accuracy: 0.0145 - val_loss: 4.3738 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3886 - accuracy: 0.0000e+00 - val_loss: 4.3721 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.3415 - accuracy: 0.0290 - val_loss: 4.3697 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 687ms/step - loss: 4.3167 - accuracy: 0.0580 - val_loss: 4.3657 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3201 - accuracy: 0.0290 - val_loss: 4.3633 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3743 - accuracy: 0.0000e+00 - val_loss: 4.3630 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.4054 - accuracy: 0.0000e+00 - val_loss: 4.3653 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3385 - accuracy: 0.0145 - val_loss: 4.3621 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3545 - accuracy: 0.0725 - val_loss: 4.3582 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3475 - accuracy: 0.0290 - val_loss: 4.3388 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.4399 - accuracy: 0.0000e+00 - val_loss: 4.3377 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3635 - accuracy: 0.0435 - val_loss: 4.3480 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3731 - accuracy: 0.0145 - val_loss: 4.3535 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.4159 - accuracy: 0.0000e+00 - val_loss: 4.3526 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3256 - accuracy: 0.0145 - val_loss: 4.3781 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.4619 - accuracy: 0.0145 - val_loss: 4.3546 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4062 - accuracy: 0.0000e+00 - val_loss: 4.3703 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 4.3183 - accuracy: 0.0145 - val_loss: 4.3670 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.4379 - accuracy: 0.0000e+00 - val_loss: 4.3705 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3220 - accuracy: 0.0290 - val_loss: 4.3711 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 625ms/step - loss: 4.3457 - accuracy: 0.0290 - val_loss: 4.3738 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3645 - accuracy: 0.0290 - val_loss: 4.3771 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3252 - accuracy: 0.0441 - val_loss: 4.3822 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.4440 - accuracy: 0.0000e+00 - val_loss: 4.3761 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3071 - accuracy: 0.0588 - val_loss: 4.3711 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.7094 - accuracy: 0.0147 - val_loss: 4.3724 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.3803 - accuracy: 0.0147 - val_loss: 4.3746 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.4009 - accuracy: 0.0147 - val_loss: 4.3756 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.3503 - accuracy: 0.0294 - val_loss: 4.3766 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3652 - accuracy: 0.0147 - val_loss: 4.3777 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3808 - accuracy: 0.0147 - val_loss: 4.3780 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 4.3613 - accuracy: 0.0294 - val_loss: 4.3800 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3628 - accuracy: 0.0147 - val_loss: 4.3789 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3839 - accuracy: 0.0294 - val_loss: 4.3773 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.3333 - accuracy: 0.0294 - val_loss: 4.3766 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3437 - accuracy: 0.0147 - val_loss: 4.3747 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.4485 - accuracy: 0.0294 - val_loss: 4.3743 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3865 - accuracy: 0.0000e+00 - val_loss: 4.3769 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 598ms/step - loss: 4.3893 - accuracy: 0.0147 - val_loss: 4.3778 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3878 - accuracy: 0.0000e+00 - val_loss: 4.3790 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3277 - accuracy: 0.0147 - val_loss: 4.3799 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3628 - accuracy: 0.0147 - val_loss: 4.3794 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 587ms/step - loss: 4.3905 - accuracy: 0.0147 - val_loss: 4.3829 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.3570 - accuracy: 0.0147 - val_loss: 4.3836 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 589ms/step - loss: 4.3937 - accuracy: 0.0294 - val_loss: 4.3818 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 575ms/step - loss: 4.3533 - accuracy: 0.0147 - val_loss: 4.3791 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.3030 - accuracy: 0.0000e+00 - val_loss: 4.3765 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 582ms/step - loss: 4.3571 - accuracy: 0.0441 - val_loss: 4.3749 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.3146 - accuracy: 0.0147 - val_loss: 4.3733 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.4024 - accuracy: 0.0588 - val_loss: 4.3723 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 669ms/step - loss: 4.3683 - accuracy: 0.0147 - val_loss: 4.3729 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 590ms/step - loss: 4.4197 - accuracy: 0.0000e+00 - val_loss: 4.3741 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 582ms/step - loss: 4.4342 - accuracy: 0.0147 - val_loss: 4.3758 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.3454 - accuracy: 0.0147 - val_loss: 4.3764 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.3180 - accuracy: 0.0441 - val_loss: 4.3786 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3498 - accuracy: 0.0147 - val_loss: 4.3802 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3721 - accuracy: 0.0000e+00 - val_loss: 4.3809 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4197 - accuracy: 0.0000e+00 - val_loss: 4.3814 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.3820 - accuracy: 0.0147 - val_loss: 4.3814 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3957 - accuracy: 0.0147 - val_loss: 4.3802 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3444 - accuracy: 0.0147 - val_loss: 4.3805 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3734 - accuracy: 0.0147 - val_loss: 4.3815 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3368 - accuracy: 0.0294 - val_loss: 4.3819 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.2664 - accuracy: 0.0000e+00 - val_loss: 4.3818 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3337 - accuracy: 0.0000e+00 - val_loss: 4.3823 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 613ms/step - loss: 4.3536 - accuracy: 0.0294 - val_loss: 4.3844 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3687 - accuracy: 0.0294 - val_loss: 4.3858 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3907 - accuracy: 0.0147 - val_loss: 4.3842 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3282 - accuracy: 0.0147 - val_loss: 4.3833 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.4094 - accuracy: 0.0000e+00 - val_loss: 4.3821 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3328 - accuracy: 0.0441 - val_loss: 4.3801 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3615 - accuracy: 0.0147 - val_loss: 4.3809 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 620ms/step - loss: 4.3740 - accuracy: 0.0000e+00 - val_loss: 4.3787 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3287 - accuracy: 0.0294 - val_loss: 4.3784 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 4.3929 - accuracy: 0.0000e+00 - val_loss: 4.3803 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 591ms/step - loss: 4.3452 - accuracy: 0.0147 - val_loss: 4.3828 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 592ms/step - loss: 4.3395 - accuracy: 0.0294 - val_loss: 4.3857 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3519 - accuracy: 0.0000e+00 - val_loss: 4.3865 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 583ms/step - loss: 4.3478 - accuracy: 0.0147 - val_loss: 4.3882 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.4426 - accuracy: 0.0441 - val_loss: 4.3899 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3569 - accuracy: 0.0147 - val_loss: 4.3801 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.4384 - accuracy: 0.0147 - val_loss: 4.3817 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.3690 - accuracy: 0.0294 - val_loss: 4.3848 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 637ms/step - loss: 4.3628 - accuracy: 0.0147 - val_loss: 4.3915 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 633ms/step - loss: 4.3393 - accuracy: 0.0147 - val_loss: 4.3954 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 597ms/step - loss: 4.3567 - accuracy: 0.0441 - val_loss: 4.3884 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3463 - accuracy: 0.0588 - val_loss: 4.3820 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3033 - accuracy: 0.0147 - val_loss: 4.3802 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 594ms/step - loss: 4.4286 - accuracy: 0.0294 - val_loss: 4.3725 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3695 - accuracy: 0.0294 - val_loss: 4.3698 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 618ms/step - loss: 4.3536 - accuracy: 0.0147 - val_loss: 4.3754 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 601ms/step - loss: 4.3266 - accuracy: 0.0000e+00 - val_loss: 4.3781 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3420 - accuracy: 0.0147 - val_loss: 4.3779 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3267 - accuracy: 0.0000e+00 - val_loss: 4.3768 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3912 - accuracy: 0.0147 - val_loss: 4.3757 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 593ms/step - loss: 4.3375 - accuracy: 0.0294 - val_loss: 4.3748 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 606ms/step - loss: 4.3897 - accuracy: 0.0147 - val_loss: 4.3738 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 639ms/step - loss: 4.3414 - accuracy: 0.0147 - val_loss: 4.3717 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 602ms/step - loss: 4.2971 - accuracy: 0.0000e+00 - val_loss: 4.3714 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 600ms/step - loss: 4.3745 - accuracy: 0.0000e+00 - val_loss: 4.3710 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 599ms/step - loss: 4.4465 - accuracy: 0.0147 - val_loss: 4.3704 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 586ms/step - loss: 4.3790 - accuracy: 0.0147 - val_loss: 4.3693 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 595ms/step - loss: 4.3547 - accuracy: 0.0147 - val_loss: 4.3691 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3552 - accuracy: 0.0000e+00 - val_loss: 4.3689 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 4.3460 - accuracy: 0.0294 - val_loss: 4.3685 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 604ms/step - loss: 4.3764 - accuracy: 0.0147 - val_loss: 4.3678 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 580ms/step - loss: 4.3299 - accuracy: 0.0294 - val_loss: 4.3666 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 610ms/step - loss: 4.4170 - accuracy: 0.0441 - val_loss: 4.3662 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 609ms/step - loss: 4.3584 - accuracy: 0.0294 - val_loss: 4.3656 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 603ms/step - loss: 4.3472 - accuracy: 0.0441 - val_loss: 4.3653 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 4.3819 - accuracy: 0.0000e+00 - val_loss: 4.3670 - val_accuracy: 0.0000e+00\n",
      "3/3 [==============================] - 2s 605ms/step - loss: 4.3233 - accuracy: 0.0294 - val_loss: 4.3688 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "for i in range(0,3):\n",
    "    for batch_n in range(200):\n",
    "        X = load_images(X_train_batches[batch_n], resized_train_dir)\n",
    "        Y = encode(y_train_batches[batch_n])\n",
    "        test_images = load_images(X_test_batches[0], resized_train_dir)\n",
    "        test_labels = encode(y_test_batches[0])\n",
    "        history.append(model.fit(X, Y, validation_data=(test_images, test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_list_to_single(history_list):\n",
    "    res = defaultdict(list)\n",
    "    for h in history_list:\n",
    "        for k in h.history.keys():\n",
    "            res[k] = res[k] + h.history[k]\n",
    "    return res\n",
    "\n",
    "new_history = history_list_to_single(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(new_history['accuracy'], label='accuracy')\n",
    "plt.plot(new_history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 50, 50, 32)   864         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 50, 50, 32)   128         ['Conv1[0][0]']                  \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 50, 50, 32)   0           ['bn_Conv1[0][0]']               \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 50, 50, 32)  288         ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 50, 50, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 50, 50, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                                                           ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 50, 50, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 50, 50, 16)  64          ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 50, 50, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 50, 50, 96)  384         ['block_1_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 50, 50, 96)   0           ['block_1_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 51, 51, 96)   0           ['block_1_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 25, 25, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 25, 25, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 25, 25, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 25, 25, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 25, 25, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 25, 25, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 25, 25, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 25, 25, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 25, 25, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 25, 25, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 25, 25, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 25, 25, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 25, 25, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 25, 25, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 25, 25, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 25, 25, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 25, 25, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 27, 27, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 13, 13, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 13, 13, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 13, 13, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 13, 13, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 13, 13, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 13, 13, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 13, 13, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 13, 13, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 13, 13, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 13, 13, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 13, 13, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 13, 13, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 13, 13, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 13, 13, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 13, 13, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 13, 13, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 13, 13, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 13, 13, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 13, 13, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 13, 13, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 13, 13, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 13, 13, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 13, 13, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 13, 13, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 13, 13, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 13, 13, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 15, 15, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 7, 7, 192)   1728        ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 7, 7, 192)   768         ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 7, 7, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 7, 7, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 7, 7, 64)    256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 7, 7, 384)    24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 7, 7, 384)   1536        ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 7, 7, 384)    0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 7, 7, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 7, 7, 384)   1536        ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 7, 7, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 7, 7, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 7, 7, 64)    256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 7, 7, 64)     0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 7, 7, 384)    24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 7, 7, 384)   1536        ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 7, 7, 384)    0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 7, 7, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 7, 7, 384)   1536        ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 7, 7, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 7, 7, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 7, 7, 64)    256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 7, 7, 64)     0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 7, 7, 384)    24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 7, 7, 384)   1536        ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 7, 7, 384)    0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 7, 7, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 7, 7, 384)   1536        ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 7, 7, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 7, 7, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 7, 7, 64)    256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 7, 7, 64)     0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 7, 7, 384)    24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 7, 7, 384)   1536        ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 7, 7, 384)    0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 7, 7, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 7, 7, 384)   1536        ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 7, 7, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 7, 7, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 7, 7, 96)    384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 7, 7, 576)    55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 7, 7, 576)   2304        ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 7, 7, 576)    0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 7, 7, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 7, 7, 96)    384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 7, 7, 96)     0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 7, 7, 576)    55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 7, 7, 576)   2304        ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 7, 7, 576)    0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 7, 7, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 7, 7, 96)    384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 7, 7, 96)     0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 7, 7, 576)    55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 7, 7, 576)   2304        ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 7, 7, 576)    0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 9, 9, 576)    0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 4, 4, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 4, 4, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 4, 4, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 4, 4, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 4, 4, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 4, 4, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 4, 4, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 4, 4, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 4, 4, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 0\n",
      "Non-trainable params: 2,257,984\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = img_size + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  global_average_layer,\n",
    "  prediction_layer\n",
    "])\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 4, 4, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                102480    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,360,464\n",
      "Trainable params: 102,480\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0610 - accuracy: 0.1739 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0609 - accuracy: 0.1304 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0607 - accuracy: 0.1739 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0578 - accuracy: 0.1884 - val_loss: 0.0718 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0626 - accuracy: 0.1159 - val_loss: 0.0719 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0608 - accuracy: 0.0870 - val_loss: 0.0719 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0589 - accuracy: 0.1304 - val_loss: 0.0720 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0585 - accuracy: 0.1594 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0607 - accuracy: 0.1304 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0603 - accuracy: 0.1594 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0586 - accuracy: 0.2029 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0596 - accuracy: 0.1304 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0616 - accuracy: 0.1739 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0632 - accuracy: 0.0580 - val_loss: 0.0713 - val_accuracy: 0.0294\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0590 - accuracy: 0.1304 - val_loss: 0.0716 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0592 - accuracy: 0.1739 - val_loss: 0.0716 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0566 - accuracy: 0.1594 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0614 - accuracy: 0.1304 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0605 - accuracy: 0.1449 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0583 - accuracy: 0.1449 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0715 - accuracy: 0.0435 - val_loss: 0.0713 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0742 - accuracy: 0.0290 - val_loss: 0.0713 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0704 - accuracy: 0.0580 - val_loss: 0.0714 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0700 - accuracy: 0.0290 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0700 - accuracy: 0.0435 - val_loss: 0.0718 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0715 - accuracy: 0.0580 - val_loss: 0.0713 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0701 - accuracy: 0.0725 - val_loss: 0.0715 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0691 - accuracy: 0.0145 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0697 - accuracy: 0.0435 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0697 - accuracy: 0.0290 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0694 - accuracy: 0.0580 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0709 - accuracy: 0.0580 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0679 - accuracy: 0.0290 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0683 - accuracy: 0.0870 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0687 - accuracy: 0.0435 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0692 - accuracy: 0.0870 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0704 - accuracy: 0.0725 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0687 - accuracy: 0.0290 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0698 - accuracy: 0.0290 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0638 - accuracy: 0.0290 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 271ms/step - loss: 0.0688 - accuracy: 0.0725 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0714 - accuracy: 0.0290 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0682 - accuracy: 0.0725 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0702 - accuracy: 0.0145 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0688 - accuracy: 0.0290 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0701 - accuracy: 0.0580 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0682 - accuracy: 0.0725 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0694 - accuracy: 0.0290 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0733 - accuracy: 0.0725 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0721 - accuracy: 0.0435 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0696 - accuracy: 0.0145 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0717 - accuracy: 0.0435 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0709 - accuracy: 0.0435 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0699 - accuracy: 0.0435 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0732 - accuracy: 0.0145 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0716 - accuracy: 0.0435 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0697 - accuracy: 0.0580 - val_loss: 0.0716 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0706 - accuracy: 0.0435 - val_loss: 0.0714 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0691 - accuracy: 0.0580 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0666 - accuracy: 0.0290 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0693 - accuracy: 0.0725 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0695 - accuracy: 0.0435 - val_loss: 0.0713 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0693 - accuracy: 0.0580 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0729 - accuracy: 0.0290 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0145 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0707 - accuracy: 0.0435 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0699 - accuracy: 0.0290 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0736 - accuracy: 0.0145 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0710 - accuracy: 0.0435 - val_loss: 0.0709 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0685 - accuracy: 0.0580 - val_loss: 0.0715 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - accuracy: 0.0870 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0699 - accuracy: 0.0435 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0694 - accuracy: 0.0290 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0720 - accuracy: 0.0145 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0676 - accuracy: 0.1014 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0706 - accuracy: 0.0725 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0649 - accuracy: 0.1159 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.0665 - accuracy: 0.0435 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 0.0680 - accuracy: 0.0290 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 180ms/step - loss: 0.0690 - accuracy: 0.0290 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0698 - accuracy: 0.0435 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 0.0699 - accuracy: 0.0435 - val_loss: 0.0702 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0710 - accuracy: 0.0580 - val_loss: 0.0705 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0739 - accuracy: 0.0145 - val_loss: 0.0708 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0694 - accuracy: 0.0725 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0705 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0683 - accuracy: 0.0725 - val_loss: 0.0703 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0678 - accuracy: 0.0870 - val_loss: 0.0707 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0677 - accuracy: 0.0725 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0682 - accuracy: 0.0435 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0684 - accuracy: 0.0435 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0685 - accuracy: 0.0435 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0714 - accuracy: 0.0145 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0731 - accuracy: 0.0290 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0696 - accuracy: 0.0435 - val_loss: 0.0706 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0710 - accuracy: 0.0580 - val_loss: 0.0707 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0692 - accuracy: 0.0725 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0721 - accuracy: 0.0435 - val_loss: 0.0709 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0682 - accuracy: 0.0725 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0694 - accuracy: 0.0580 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0695 - accuracy: 0.0290 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0720 - accuracy: 0.0580 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0680 - accuracy: 0.0870 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0709 - accuracy: 0.0290 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0693 - accuracy: 0.0145 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0736 - accuracy: 0.0145 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0690 - accuracy: 0.0435 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0728 - accuracy: 0.0580 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0696 - accuracy: 0.0580 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0704 - accuracy: 0.0294 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0696 - accuracy: 0.0735 - val_loss: 0.0708 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0699 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0732 - accuracy: 0.0735 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0698 - accuracy: 0.0294 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0705 - accuracy: 0.0588 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0707 - accuracy: 0.0294 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0685 - accuracy: 0.0441 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0704 - accuracy: 0.0588 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0711 - accuracy: 0.1324 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0689 - accuracy: 0.0441 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0695 - accuracy: 0.0441 - val_loss: 0.0699 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0695 - accuracy: 0.0147 - val_loss: 0.0701 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0701 - accuracy: 0.0441 - val_loss: 0.0705 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0705 - accuracy: 0.0441 - val_loss: 0.0703 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0689 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0699 - accuracy: 0.0294 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0749 - accuracy: 0.0147 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0693 - accuracy: 0.0147 - val_loss: 0.0705 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0704 - accuracy: 0.0294 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0697 - accuracy: 0.0588 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0735 - accuracy: 0.0294 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0740 - accuracy: 0.0147 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0711 - accuracy: 0.0294 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0719 - accuracy: 0.0147 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0700 - accuracy: 0.0441 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0699 - accuracy: 0.0147 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0294 - val_loss: 0.0696 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0700 - accuracy: 0.0441 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0722 - accuracy: 0.0294 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0708 - accuracy: 0.0294 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0695 - accuracy: 0.0588 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0694 - accuracy: 0.0588 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0726 - accuracy: 0.0735 - val_loss: 0.0709 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0694 - accuracy: 0.1029 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0704 - accuracy: 0.0147 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0690 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0677 - accuracy: 0.0735 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0712 - accuracy: 0.0294 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0727 - accuracy: 0.0735 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0721 - accuracy: 0.0588 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0684 - accuracy: 0.0147 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0706 - accuracy: 0.0147 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.04 - 0s 140ms/step - loss: 0.0711 - accuracy: 0.0441 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0722 - accuracy: 0.0147 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0681 - accuracy: 0.0735 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0683 - accuracy: 0.0735 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0726 - accuracy: 0.0441 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0666 - accuracy: 0.0588 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0695 - accuracy: 0.0441 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0718 - accuracy: 0.0882 - val_loss: 0.0696 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0682 - accuracy: 0.0588 - val_loss: 0.0700 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0771 - accuracy: 0.0000e+00 - val_loss: 0.0698 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0699 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0714 - accuracy: 0.0294 - val_loss: 0.0698 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0708 - accuracy: 0.0441 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0705 - accuracy: 0.0000e+00 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0738 - accuracy: 0.0588 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0705 - accuracy: 0.0441 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0698 - accuracy: 0.0147 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0650 - accuracy: 0.0441 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0727 - accuracy: 0.0294 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0677 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0688 - accuracy: 0.0147 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0690 - accuracy: 0.0294 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0689 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0691 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0716 - accuracy: 0.0441 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0694 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0717 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0708 - accuracy: 0.0735 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0688 - accuracy: 0.1176 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0294 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0709 - accuracy: 0.0000e+00 - val_loss: 0.0700 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0710 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0687 - accuracy: 0.0000e+00 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0694 - accuracy: 0.0441 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0726 - accuracy: 0.0147 - val_loss: 0.0705 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0698 - accuracy: 0.0441 - val_loss: 0.0707 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0709 - accuracy: 0.0735 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0677 - accuracy: 0.0588 - val_loss: 0.0708 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0703 - accuracy: 0.0147 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0690 - accuracy: 0.0147 - val_loss: 0.0711 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0700 - accuracy: 0.0441 - val_loss: 0.0711 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0756 - accuracy: 0.0294 - val_loss: 0.0703 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0722 - accuracy: 0.0294 - val_loss: 0.0703 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0715 - accuracy: 0.0588 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0699 - accuracy: 0.0294 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0705 - accuracy: 0.0882 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0676 - accuracy: 0.0735 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0666 - accuracy: 0.0441 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0698 - accuracy: 0.0294 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0680 - accuracy: 0.0294 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0679 - accuracy: 0.0882 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0704 - accuracy: 0.0441 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0698 - accuracy: 0.1029 - val_loss: 0.0709 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0701 - accuracy: 0.0735 - val_loss: 0.0709 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0673 - accuracy: 0.0588 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0726 - accuracy: 0.0588 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0739 - accuracy: 0.1029 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0647 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0695 - accuracy: 0.0441 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0720 - accuracy: 0.0441 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0729 - accuracy: 0.0147 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0724 - accuracy: 0.0441 - val_loss: 0.0704 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0712 - accuracy: 0.0735 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0714 - accuracy: 0.0588 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0697 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0678 - accuracy: 0.1029 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0699 - accuracy: 0.0000e+00 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0703 - accuracy: 0.0735 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0717 - accuracy: 0.0588 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0678 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0708 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0668 - accuracy: 0.0735 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.0709 - accuracy: 0.0147 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0724 - accuracy: 0.0441 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0696 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0741 - accuracy: 0.0147 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0721 - accuracy: 0.0294 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0672 - accuracy: 0.0147 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0719 - accuracy: 0.0441 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0670 - accuracy: 0.0588 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0699 - accuracy: 0.0294 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0701 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0722 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0728 - accuracy: 0.0000e+00 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0707 - accuracy: 0.0735 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0718 - accuracy: 0.0294 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0700 - accuracy: 0.0882 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0705 - accuracy: 0.0147 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0719 - accuracy: 0.0294 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0693 - accuracy: 0.0588 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0718 - accuracy: 0.0441 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0701 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0714 - accuracy: 0.0441 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0699 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0708 - accuracy: 0.0294 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0691 - accuracy: 0.0000e+00 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0733 - accuracy: 0.0147 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0711 - accuracy: 0.0735 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0691 - accuracy: 0.0441 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0679 - accuracy: 0.0735 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0739 - accuracy: 0.0588 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0699 - accuracy: 0.1176 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0620 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0714 - accuracy: 0.0735 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0679 - accuracy: 0.0294 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0723 - accuracy: 0.0441 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0689 - accuracy: 0.0147 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0682 - accuracy: 0.0588 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0685 - accuracy: 0.0588 - val_loss: 0.0694 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0691 - accuracy: 0.0441 - val_loss: 0.0691 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0716 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0699 - accuracy: 0.0294 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0726 - accuracy: 0.0294 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0676 - accuracy: 0.0441 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0706 - accuracy: 0.0294 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0691 - accuracy: 0.0588 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0766 - accuracy: 0.0294 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0702 - accuracy: 0.0294 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0734 - accuracy: 0.0147 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0707 - accuracy: 0.1029 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0664 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0711 - accuracy: 0.0294 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0665 - accuracy: 0.0441 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0699 - accuracy: 0.0735 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0681 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0735 - accuracy: 0.0147 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0673 - accuracy: 0.0588 - val_loss: 0.0681 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0685 - accuracy: 0.0294 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0705 - accuracy: 0.0735 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0698 - accuracy: 0.0735 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0675 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0716 - accuracy: 0.0441 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0700 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0649 - accuracy: 0.0588 - val_loss: 0.0676 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0707 - accuracy: 0.0441 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0707 - accuracy: 0.0882 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0698 - accuracy: 0.0294 - val_loss: 0.0671 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0704 - accuracy: 0.0588 - val_loss: 0.0674 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0651 - accuracy: 0.1176 - val_loss: 0.0676 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0600 - accuracy: 0.1594 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0628 - accuracy: 0.1304 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0590 - accuracy: 0.1594 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0590 - accuracy: 0.1304 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0622 - accuracy: 0.1739 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0621 - accuracy: 0.1304 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0602 - accuracy: 0.1304 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0578 - accuracy: 0.1014 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0605 - accuracy: 0.1449 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0598 - accuracy: 0.1594 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0590 - accuracy: 0.2319 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0593 - accuracy: 0.1159 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0610 - accuracy: 0.1449 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0635 - accuracy: 0.0290 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0587 - accuracy: 0.1594 - val_loss: 0.0685 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0600 - accuracy: 0.1449 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0580 - accuracy: 0.1594 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0602 - accuracy: 0.1304 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0602 - accuracy: 0.1884 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0583 - accuracy: 0.1739 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0695 - accuracy: 0.0580 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0711 - accuracy: 0.0290 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0689 - accuracy: 0.0435 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0684 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0674 - accuracy: 0.0580 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0697 - accuracy: 0.0725 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0667 - accuracy: 0.0725 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0683 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0679 - accuracy: 0.0580 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0669 - accuracy: 0.0580 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0689 - accuracy: 0.0870 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0653 - accuracy: 0.0580 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0678 - accuracy: 0.0725 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0655 - accuracy: 0.1014 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0671 - accuracy: 0.1304 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0689 - accuracy: 0.0870 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0669 - accuracy: 0.1014 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0680 - accuracy: 0.0435 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0634 - accuracy: 0.0435 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0675 - accuracy: 0.1014 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0700 - accuracy: 0.0435 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0671 - accuracy: 0.0580 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0666 - accuracy: 0.0435 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0689 - accuracy: 0.0290 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0678 - accuracy: 0.0580 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0669 - accuracy: 0.0435 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0690 - accuracy: 0.0435 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0713 - accuracy: 0.1014 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0705 - accuracy: 0.0435 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0682 - accuracy: 0.0435 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0702 - accuracy: 0.0725 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0693 - accuracy: 0.0725 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0681 - accuracy: 0.0725 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0714 - accuracy: 0.0435 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0697 - accuracy: 0.0870 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 0.0678 - accuracy: 0.0435 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0692 - accuracy: 0.0435 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0675 - accuracy: 0.0580 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0660 - accuracy: 0.0435 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0683 - accuracy: 0.1014 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0688 - accuracy: 0.0580 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0673 - accuracy: 0.0870 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0713 - accuracy: 0.0290 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0671 - accuracy: 0.0290 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0681 - accuracy: 0.0580 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0692 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0722 - accuracy: 0.0290 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0696 - accuracy: 0.0435 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0668 - accuracy: 0.1014 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0645 - accuracy: 0.1449 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0679 - accuracy: 0.0435 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0686 - accuracy: 0.0290 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0709 - accuracy: 0.0725 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0657 - accuracy: 0.0870 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0682 - accuracy: 0.0725 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0633 - accuracy: 0.1449 - val_loss: 0.0685 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0642 - accuracy: 0.1014 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0673 - accuracy: 0.0290 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0673 - accuracy: 0.0435 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0683 - accuracy: 0.0435 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0690 - accuracy: 0.0725 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0682 - accuracy: 0.0870 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0725 - accuracy: 0.0435 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0694 - accuracy: 0.0870 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0666 - accuracy: 0.0870 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0667 - accuracy: 0.1014 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0654 - accuracy: 0.1304 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0657 - accuracy: 0.0725 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0675 - accuracy: 0.1159 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0672 - accuracy: 0.0725 - val_loss: 0.0681 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0670 - accuracy: 0.0580 - val_loss: 0.0679 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0705 - accuracy: 0.0580 - val_loss: 0.0681 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0723 - accuracy: 0.0725 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0682 - accuracy: 0.0580 - val_loss: 0.0684 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0699 - accuracy: 0.0435 - val_loss: 0.0686 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0684 - accuracy: 0.0870 - val_loss: 0.0682 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0706 - accuracy: 0.0580 - val_loss: 0.0687 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0670 - accuracy: 0.0870 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0689 - accuracy: 0.0580 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0680 - accuracy: 0.0725 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0703 - accuracy: 0.0435 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0666 - accuracy: 0.1014 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0697 - accuracy: 0.0435 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0673 - accuracy: 0.0290 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0715 - accuracy: 0.0725 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0677 - accuracy: 0.0435 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0713 - accuracy: 0.1014 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0676 - accuracy: 0.0870 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0707 - accuracy: 0.1176 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0692 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0680 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0715 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0686 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0693 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0685 - accuracy: 0.0735 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 270ms/step - loss: 0.0667 - accuracy: 0.0588 - val_loss: 0.0694 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0684 - accuracy: 0.0441 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0697 - accuracy: 0.1471 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0673 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0681 - accuracy: 0.0882 - val_loss: 0.0689 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0689 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0699 - accuracy: 0.0441 - val_loss: 0.0692 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0689 - accuracy: 0.0441 - val_loss: 0.0692 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0675 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0674 - accuracy: 0.0882 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0735 - accuracy: 0.0147 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0671 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0694 - accuracy: 0.0441 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0679 - accuracy: 0.0588 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0716 - accuracy: 0.0588 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0727 - accuracy: 0.0147 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0701 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0698 - accuracy: 0.0294 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0687 - accuracy: 0.0147 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0661 - accuracy: 0.0588 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0689 - accuracy: 0.0147 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0708 - accuracy: 0.0441 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0685 - accuracy: 0.0588 - val_loss: 0.0686 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0686 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0680 - accuracy: 0.0882 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0715 - accuracy: 0.0588 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0689 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0691 - accuracy: 0.0294 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0675 - accuracy: 0.1324 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0671 - accuracy: 0.1029 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0691 - accuracy: 0.0882 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0713 - accuracy: 0.0735 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0703 - accuracy: 0.0735 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0671 - accuracy: 0.0441 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0695 - accuracy: 0.0588 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0716 - accuracy: 0.0294 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0677 - accuracy: 0.1324 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0665 - accuracy: 0.1176 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0707 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0652 - accuracy: 0.1029 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0689 - accuracy: 0.0294 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0708 - accuracy: 0.1176 - val_loss: 0.0683 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0672 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0765 - accuracy: 0.0147 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0691 - accuracy: 0.0735 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0707 - accuracy: 0.0441 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0695 - accuracy: 0.0588 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0701 - accuracy: 0.0147 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0722 - accuracy: 0.0588 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0689 - accuracy: 0.0441 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0688 - accuracy: 0.0294 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0639 - accuracy: 0.0882 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0716 - accuracy: 0.0882 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0665 - accuracy: 0.1029 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0683 - accuracy: 0.0441 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0679 - accuracy: 0.1029 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0677 - accuracy: 0.0441 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0701 - accuracy: 0.0441 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0680 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0708 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0702 - accuracy: 0.0882 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0675 - accuracy: 0.1029 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0675 - accuracy: 0.0441 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 0.0705 - accuracy: 0.0147 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0702 - accuracy: 0.1176 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0688 - accuracy: 0.1471 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0676 - accuracy: 0.0294 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0684 - accuracy: 0.0735 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0712 - accuracy: 0.0294 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0682 - accuracy: 0.0588 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0709 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0662 - accuracy: 0.1176 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0691 - accuracy: 0.0441 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0681 - accuracy: 0.0294 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0698 - accuracy: 0.0588 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0742 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0705 - accuracy: 0.0294 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0685 - accuracy: 0.0882 - val_loss: 0.0691 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0703 - accuracy: 0.0588 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0694 - accuracy: 0.1471 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0664 - accuracy: 0.1029 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0689 - accuracy: 0.0588 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0649 - accuracy: 0.1176 - val_loss: 0.0698 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0700 - accuracy: 0.0147 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0670 - accuracy: 0.0147 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0666 - accuracy: 0.1029 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0696 - accuracy: 0.0588 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0696 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0697 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0668 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0735 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0628 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0686 - accuracy: 0.0441 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0709 - accuracy: 0.0588 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0716 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0712 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0700 - accuracy: 0.1176 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0705 - accuracy: 0.0588 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0735 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0661 - accuracy: 0.1176 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0693 - accuracy: 0.1176 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0685 - accuracy: 0.0000e+00 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0686 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0705 - accuracy: 0.0294 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0668 - accuracy: 0.0882 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0698 - accuracy: 0.0294 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0658 - accuracy: 0.0882 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0697 - accuracy: 0.0294 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0713 - accuracy: 0.0441 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0681 - accuracy: 0.0441 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0742 - accuracy: 0.0294 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0723 - accuracy: 0.0588 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0654 - accuracy: 0.0735 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0709 - accuracy: 0.0294 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0659 - accuracy: 0.0588 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0686 - accuracy: 0.0441 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.06 - 0s 142ms/step - loss: 0.0727 - accuracy: 0.0588 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0714 - accuracy: 0.0000e+00 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0707 - accuracy: 0.0735 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0690 - accuracy: 0.1324 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0695 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0700 - accuracy: 0.0294 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0682 - accuracy: 0.0735 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0709 - accuracy: 0.0735 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0696 - accuracy: 0.0588 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0683 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0703 - accuracy: 0.0441 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0677 - accuracy: 0.1471 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0702 - accuracy: 0.0588 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0678 - accuracy: 0.0735 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0735 - accuracy: 0.0294 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0706 - accuracy: 0.0882 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0683 - accuracy: 0.0735 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0668 - accuracy: 0.0588 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0735 - accuracy: 0.0735 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0699 - accuracy: 0.1176 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0614 - accuracy: 0.0735 - val_loss: 0.0671 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0717 - accuracy: 0.0735 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0673 - accuracy: 0.0735 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0712 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0669 - accuracy: 0.1324 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0671 - accuracy: 0.0294 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0671 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0676 - accuracy: 0.0735 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0678 - accuracy: 0.0735 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0714 - accuracy: 0.0441 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0683 - accuracy: 0.0294 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0718 - accuracy: 0.0588 - val_loss: 0.0670 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0661 - accuracy: 0.0588 - val_loss: 0.0671 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0709 - accuracy: 0.0294 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0683 - accuracy: 0.0882 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0763 - accuracy: 0.0294 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0694 - accuracy: 0.0294 - val_loss: 0.0671 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0733 - accuracy: 0.0294 - val_loss: 0.0667 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0699 - accuracy: 0.1324 - val_loss: 0.0669 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0652 - accuracy: 0.0882 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0703 - accuracy: 0.0441 - val_loss: 0.0670 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0660 - accuracy: 0.0882 - val_loss: 0.0672 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0696 - accuracy: 0.0882 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0677 - accuracy: 0.0882 - val_loss: 0.0669 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0688 - accuracy: 0.0735 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0725 - accuracy: 0.0147 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0660 - accuracy: 0.0882 - val_loss: 0.0673 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0678 - accuracy: 0.0588 - val_loss: 0.0676 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0698 - accuracy: 0.1029 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0672 - accuracy: 0.0735 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0720 - accuracy: 0.0147 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0690 - accuracy: 0.1029 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0643 - accuracy: 0.0882 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0705 - accuracy: 0.0735 - val_loss: 0.0670 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0695 - accuracy: 0.0882 - val_loss: 0.0669 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0694 - accuracy: 0.0588 - val_loss: 0.0666 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0694 - accuracy: 0.0588 - val_loss: 0.0669 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0648 - accuracy: 0.1029 - val_loss: 0.0670 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0608 - accuracy: 0.1304 - val_loss: 0.0671 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0637 - accuracy: 0.1304 - val_loss: 0.0676 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0587 - accuracy: 0.1014 - val_loss: 0.0671 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0594 - accuracy: 0.1739 - val_loss: 0.0673 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0631 - accuracy: 0.1449 - val_loss: 0.0673 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0627 - accuracy: 0.1449 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0621 - accuracy: 0.1449 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0590 - accuracy: 0.0870 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0602 - accuracy: 0.1594 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0602 - accuracy: 0.1594 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0589 - accuracy: 0.2029 - val_loss: 0.0672 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.0595 - accuracy: 0.1449 - val_loss: 0.0670 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0609 - accuracy: 0.1739 - val_loss: 0.0671 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0639 - accuracy: 0.0290 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0596 - accuracy: 0.1014 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0607 - accuracy: 0.1594 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0589 - accuracy: 0.1304 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0606 - accuracy: 0.1594 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0607 - accuracy: 0.1739 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0593 - accuracy: 0.1304 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0702 - accuracy: 0.0435 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0701 - accuracy: 0.0290 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0681 - accuracy: 0.0580 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0669 - accuracy: 0.0725 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0693 - accuracy: 0.0580 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0684 - accuracy: 0.0580 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0670 - accuracy: 0.1014 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0679 - accuracy: 0.1159 - val_loss: 0.0683 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0658 - accuracy: 0.0870 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.0625   - 0s 140ms/step - loss: 0.0687 - accuracy: 0.0725 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0643 - accuracy: 0.1159 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0671 - accuracy: 0.0870 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0650 - accuracy: 0.1014 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0668 - accuracy: 0.1304 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0683 - accuracy: 0.0725 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0666 - accuracy: 0.1014 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0677 - accuracy: 0.0725 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0639 - accuracy: 0.0290 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0670 - accuracy: 0.1159 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0698 - accuracy: 0.0725 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0675 - accuracy: 0.0870 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0656 - accuracy: 0.0725 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0685 - accuracy: 0.0580 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0673 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0681 - accuracy: 0.0725 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0666 - accuracy: 0.1014 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0695 - accuracy: 0.0725 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0716 - accuracy: 0.1014 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0701 - accuracy: 0.0580 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0679 - accuracy: 0.0435 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0700 - accuracy: 0.0870 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0688 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0677 - accuracy: 0.1159 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0711 - accuracy: 0.0580 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0696 - accuracy: 0.1159 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0671 - accuracy: 0.0870 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0692 - accuracy: 0.0725 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0658 - accuracy: 0.0580 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0677 - accuracy: 0.1304 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0697 - accuracy: 0.0870 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0673 - accuracy: 0.0870 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0712 - accuracy: 0.0145 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0666 - accuracy: 0.0580 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.14 - 0s 137ms/step - loss: 0.0678 - accuracy: 0.1304 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0691 - accuracy: 0.1014 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0724 - accuracy: 0.0435 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0695 - accuracy: 0.0725 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0654 - accuracy: 0.1594 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 0.0642 - accuracy: 0.1594 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0671 - accuracy: 0.0580 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0682 - accuracy: 0.0580 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0708 - accuracy: 0.0870 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0655 - accuracy: 0.0870 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0678 - accuracy: 0.1159 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0625 - accuracy: 0.1304 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0634 - accuracy: 0.0725 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0675 - accuracy: 0.0435 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0664 - accuracy: 0.0580 - val_loss: 0.0678 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0678 - accuracy: 0.0435 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0695 - accuracy: 0.0725 - val_loss: 0.0675 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0677 - accuracy: 0.0580 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0713 - accuracy: 0.0435 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0704 - accuracy: 0.0725 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0660 - accuracy: 0.1159 - val_loss: 0.0678 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0665 - accuracy: 0.1159 - val_loss: 0.0676 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0650 - accuracy: 0.1014 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0662 - accuracy: 0.0725 - val_loss: 0.0676 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0673 - accuracy: 0.1014 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0676 - accuracy: 0.0435 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0667 - accuracy: 0.0725 - val_loss: 0.0675 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0705 - accuracy: 0.1014 - val_loss: 0.0676 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0723 - accuracy: 0.0580 - val_loss: 0.0678 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0674 - accuracy: 0.0580 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0697 - accuracy: 0.0580 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0682 - accuracy: 0.1014 - val_loss: 0.0676 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0704 - accuracy: 0.0725 - val_loss: 0.0677 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0675 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0683 - accuracy: 0.1014 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0672 - accuracy: 0.0870 - val_loss: 0.0669 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0699 - accuracy: 0.1014 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0663 - accuracy: 0.1014 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0695 - accuracy: 0.0725 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0664 - accuracy: 0.0725 - val_loss: 0.0671 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0714 - accuracy: 0.0870 - val_loss: 0.0671 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.06 - 0s 141ms/step - loss: 0.0673 - accuracy: 0.0580 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0715 - accuracy: 0.1159 - val_loss: 0.0677 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0707 - accuracy: 0.0735 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0676 - accuracy: 0.1324 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0703 - accuracy: 0.1029 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0681 - accuracy: 0.0441 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0686 - accuracy: 0.0882 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0674 - accuracy: 0.1029 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0665 - accuracy: 0.0882 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0678 - accuracy: 0.1029 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0696 - accuracy: 0.1618 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0663 - accuracy: 0.1324 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0674 - accuracy: 0.1471 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0692 - accuracy: 0.0588 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0705 - accuracy: 0.0735 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0683 - accuracy: 0.0588 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0666 - accuracy: 0.0735 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0669 - accuracy: 0.1029 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0732 - accuracy: 0.0147 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0656 - accuracy: 0.0735 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0692 - accuracy: 0.0588 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0670 - accuracy: 0.1324 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0714 - accuracy: 0.0441 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0728 - accuracy: 0.0294 - val_loss: 0.0676 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0691 - accuracy: 0.0735 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0690 - accuracy: 0.0882 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0686 - accuracy: 0.0294 - val_loss: 0.0675 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0683 - accuracy: 0.0735 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.0656 - accuracy: 0.1029 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0686 - accuracy: 0.0294 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0705 - accuracy: 0.0588 - val_loss: 0.0678 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0685 - accuracy: 0.0441 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0687 - accuracy: 0.1029 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0678 - accuracy: 0.0735 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0710 - accuracy: 0.0735 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0682 - accuracy: 0.1176 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0686 - accuracy: 0.0294 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0661 - accuracy: 0.1471 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0669 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0882 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0713 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0698 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0665 - accuracy: 0.0441 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0691 - accuracy: 0.0735 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0693 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0715 - accuracy: 0.0441 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0685 - accuracy: 0.1029 - val_loss: 0.0681 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0664 - accuracy: 0.1324 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0703 - accuracy: 0.1029 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0644 - accuracy: 0.1029 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0684 - accuracy: 0.0588 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0704 - accuracy: 0.1176 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0670 - accuracy: 0.0441 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0764 - accuracy: 0.0294 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0687 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0706 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0697 - accuracy: 0.0882 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0699 - accuracy: 0.0441 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0718 - accuracy: 0.0588 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0688 - accuracy: 0.0441 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0685 - accuracy: 0.0441 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0638 - accuracy: 0.1029 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0724 - accuracy: 0.1029 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0669 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0681 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0674 - accuracy: 0.1324 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0670 - accuracy: 0.0588 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0667 - accuracy: 0.0588 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0709 - accuracy: 0.0882 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0699 - accuracy: 0.0882 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0677 - accuracy: 0.1324 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0673 - accuracy: 0.0882 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0698 - accuracy: 0.0147 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0698 - accuracy: 0.1176 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0692 - accuracy: 0.1471 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0673 - accuracy: 0.0441 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0687 - accuracy: 0.0882 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0717 - accuracy: 0.0294 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0676 - accuracy: 0.0735 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0718 - accuracy: 0.0735 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0652 - accuracy: 0.0882 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0691 - accuracy: 0.0588 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0672 - accuracy: 0.0294 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0700 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0739 - accuracy: 0.0588 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0698 - accuracy: 0.0294 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0689 - accuracy: 0.0735 - val_loss: 0.0694 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0710 - accuracy: 0.0735 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0694 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0663 - accuracy: 0.1324 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0684 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0642 - accuracy: 0.1471 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0703 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0667 - accuracy: 0.0294 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0665 - accuracy: 0.0882 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0698 - accuracy: 0.0735 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0702 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0703 - accuracy: 0.0882 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0673 - accuracy: 0.0588 - val_loss: 0.0697 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0719 - accuracy: 0.0882 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0739 - accuracy: 0.1029 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0624 - accuracy: 0.1176 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0686 - accuracy: 0.0588 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0709 - accuracy: 0.0588 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0707 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0700 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0691 - accuracy: 0.1029 - val_loss: 0.0689 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0708 - accuracy: 0.0588 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0682 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0657 - accuracy: 0.1324 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0695 - accuracy: 0.1029 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0675 - accuracy: 0.0000e+00 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0682 - accuracy: 0.1176 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0709 - accuracy: 0.0735 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0668 - accuracy: 0.0735 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0699 - accuracy: 0.0294 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0657 - accuracy: 0.0882 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0703 - accuracy: 0.0441 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0714 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0676 - accuracy: 0.0882 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0743 - accuracy: 0.0147 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0726 - accuracy: 0.0735 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0645 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0704 - accuracy: 0.0882 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0650 - accuracy: 0.1029 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0676 - accuracy: 0.0441 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0694 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0734 - accuracy: 0.0588 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0718 - accuracy: 0.0147 - val_loss: 0.0677 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0693 - accuracy: 0.0735 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0709 - accuracy: 0.0882 - val_loss: 0.0670 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0693 - accuracy: 0.0882 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0699 - accuracy: 0.0441 - val_loss: 0.0674 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0672 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0679 - accuracy: 0.0735 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0708 - accuracy: 0.0882 - val_loss: 0.0677 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0692 - accuracy: 0.0588 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0682 - accuracy: 0.0882 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0707 - accuracy: 0.0441 - val_loss: 0.0676 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0677 - accuracy: 0.0882 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0700 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - accuracy: 0.1176 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0740 - accuracy: 0.0147 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0711 - accuracy: 0.0882 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0677 - accuracy: 0.0735 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0659 - accuracy: 0.0735 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0735 - accuracy: 0.0735 - val_loss: 0.0675 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0698 - accuracy: 0.1324 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0605 - accuracy: 0.1176 - val_loss: 0.0673 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0718 - accuracy: 0.0882 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0709 - accuracy: 0.0735 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0666 - accuracy: 0.1618 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 0.0662 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0667 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0669 - accuracy: 0.0882 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0708 - accuracy: 0.0441 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0683 - accuracy: 0.0588 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0721 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0652 - accuracy: 0.0882 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0713 - accuracy: 0.0588 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0685 - accuracy: 0.0735 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0765 - accuracy: 0.0294 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0695 - accuracy: 0.0294 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0739 - accuracy: 0.0441 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0701 - accuracy: 0.1324 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0654 - accuracy: 0.1324 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0707 - accuracy: 0.0294 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0654 - accuracy: 0.0588 - val_loss: 0.0677 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0707 - accuracy: 0.0882 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0675 - accuracy: 0.0588 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0691 - accuracy: 0.0588 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0727 - accuracy: 0.0441 - val_loss: 0.0676 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0653 - accuracy: 0.0882 - val_loss: 0.0676 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0683 - accuracy: 0.0588 - val_loss: 0.0678 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0699 - accuracy: 0.1029 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0695 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0663 - accuracy: 0.1324 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0692 - accuracy: 0.1029 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0732 - accuracy: 0.0441 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0692 - accuracy: 0.1029 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0641 - accuracy: 0.1029 - val_loss: 0.0678 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0704 - accuracy: 0.0588 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0689 - accuracy: 0.1324 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0692 - accuracy: 0.0882 - val_loss: 0.0670 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0686 - accuracy: 0.1029 - val_loss: 0.0672 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0642 - accuracy: 0.1471 - val_loss: 0.0672 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0607 - accuracy: 0.1739 - val_loss: 0.0674 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0651 - accuracy: 0.1304 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0585 - accuracy: 0.1449 - val_loss: 0.0673 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0600 - accuracy: 0.2029 - val_loss: 0.0675 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0635 - accuracy: 0.1594 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0633 - accuracy: 0.1739 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0630 - accuracy: 0.1594 - val_loss: 0.0680 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0595 - accuracy: 0.1159 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0606 - accuracy: 0.2029 - val_loss: 0.0678 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0605 - accuracy: 0.2029 - val_loss: 0.0682 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0593 - accuracy: 0.2174 - val_loss: 0.0677 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0598 - accuracy: 0.1304 - val_loss: 0.0675 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0610 - accuracy: 0.1594 - val_loss: 0.0675 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0644 - accuracy: 0.0435 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0590 - accuracy: 0.1739 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0618 - accuracy: 0.1739 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0602 - accuracy: 0.2174 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0610 - accuracy: 0.1739 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0614 - accuracy: 0.2029 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0596 - accuracy: 0.1594 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0701 - accuracy: 0.0435 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0690 - accuracy: 0.0580 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0691 - accuracy: 0.0580 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0680 - accuracy: 0.0725 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0665 - accuracy: 0.1159 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.0693 - accuracy: 0.0580 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0678 - accuracy: 0.0725 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0671 - accuracy: 0.1449 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0690 - accuracy: 0.0580 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0678 - accuracy: 0.0725 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0650 - accuracy: 0.1159 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0685 - accuracy: 0.0725 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0642 - accuracy: 0.1159 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0672 - accuracy: 0.0870 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0648 - accuracy: 0.1014 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0667 - accuracy: 0.1304 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0870 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0659 - accuracy: 0.0870 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0679 - accuracy: 0.1014 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0641 - accuracy: 0.0580 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0669 - accuracy: 0.1304 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0696 - accuracy: 0.0870 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0675 - accuracy: 0.0870 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0653 - accuracy: 0.0580 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0682 - accuracy: 0.0580 - val_loss: 0.0696 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0673 - accuracy: 0.1014 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0679 - accuracy: 0.0580 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0662 - accuracy: 0.0725 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0702 - accuracy: 0.1014 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0714 - accuracy: 0.1304 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0698 - accuracy: 0.0580 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0668 - accuracy: 0.0725 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0700 - accuracy: 0.0870 - val_loss: 0.0691 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0680 - accuracy: 0.0580 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0679 - accuracy: 0.0725 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0714 - accuracy: 0.0290 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0702 - accuracy: 0.0870 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0661 - accuracy: 0.1304 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0692 - accuracy: 0.0580 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0668 - accuracy: 0.1159 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0654 - accuracy: 0.0725 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0677 - accuracy: 0.1449 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0704 - accuracy: 0.1014 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0672 - accuracy: 0.1014 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0718 - accuracy: 0.0290 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0665 - accuracy: 0.0725 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0684 - accuracy: 0.1304 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0696 - accuracy: 0.1159 - val_loss: 0.0690 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0729 - accuracy: 0.0580 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0699 - accuracy: 0.1014 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0657 - accuracy: 0.1449 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0641 - accuracy: 0.1304 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0670 - accuracy: 0.0290 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0693 - accuracy: 0.0580 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0701 - accuracy: 0.0725 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0655 - accuracy: 0.1159 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0675 - accuracy: 0.1159 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0625 - accuracy: 0.1449 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0634 - accuracy: 0.0870 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0675 - accuracy: 0.0290 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0664 - accuracy: 0.0870 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0679 - accuracy: 0.0725 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0695 - accuracy: 0.1159 - val_loss: 0.0680 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0675 - accuracy: 0.0725 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0717 - accuracy: 0.0580 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0707 - accuracy: 0.0580 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0665 - accuracy: 0.1159 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0673 - accuracy: 0.1159 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0653 - accuracy: 0.1159 - val_loss: 0.0686 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0667 - accuracy: 0.0435 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0678 - accuracy: 0.1159 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 0.0682 - accuracy: 0.0725 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0665 - accuracy: 0.0725 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0707 - accuracy: 0.1159 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0727 - accuracy: 0.0580 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0668 - accuracy: 0.1014 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0698 - accuracy: 0.0435 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0681 - accuracy: 0.1014 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0704 - accuracy: 0.1014 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0667 - accuracy: 0.1014 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0683 - accuracy: 0.1159 - val_loss: 0.0684 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0667 - accuracy: 0.0870 - val_loss: 0.0683 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0701 - accuracy: 0.0870 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0662 - accuracy: 0.1159 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0699 - accuracy: 0.0580 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0659 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0719 - accuracy: 0.0870 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0676 - accuracy: 0.0725 - val_loss: 0.0688 - val_accuracy: 0.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0709 - accuracy: 0.1304 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0691 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0711 - accuracy: 0.1029 - val_loss: 0.0694 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0695 - accuracy: 0.0588 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0672 - accuracy: 0.1029 - val_loss: 0.0691 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0699 - accuracy: 0.1029 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0683 - accuracy: 0.0882 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0688 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0669 - accuracy: 0.1324 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0658 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0670 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0695 - accuracy: 0.1618 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0665 - accuracy: 0.1471 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0669 - accuracy: 0.1765 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0704 - accuracy: 0.0441 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0702 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0678 - accuracy: 0.0588 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0666 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0671 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0739 - accuracy: 0.0441 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0652 - accuracy: 0.0882 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0691 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0675 - accuracy: 0.1471 - val_loss: 0.0681 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0726 - accuracy: 0.0735 - val_loss: 0.0680 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0727 - accuracy: 0.0882 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0697 - accuracy: 0.0882 - val_loss: 0.0678 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0693 - accuracy: 0.0882 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0683 - accuracy: 0.0735 - val_loss: 0.0675 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0670 - accuracy: 0.1176 - val_loss: 0.0671 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0660 - accuracy: 0.1176 - val_loss: 0.0674 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0692 - accuracy: 0.0294 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0705 - accuracy: 0.0588 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0682 - accuracy: 0.0882 - val_loss: 0.0679 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0690 - accuracy: 0.1029 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0681 - accuracy: 0.0882 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0710 - accuracy: 0.0882 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0679 - accuracy: 0.1618 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0686 - accuracy: 0.0735 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0664 - accuracy: 0.1471 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0683 - accuracy: 0.1324 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0712 - accuracy: 0.0882 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0698 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0664 - accuracy: 0.0735 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0693 - accuracy: 0.1471 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0694 - accuracy: 0.1029 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0714 - accuracy: 0.0441 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0694 - accuracy: 0.1176 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.0664 - accuracy: 0.1618 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0637 - accuracy: 0.1324 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0679 - accuracy: 0.0588 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0710 - accuracy: 0.1324 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0672 - accuracy: 0.0735 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0770 - accuracy: 0.0147 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0683 - accuracy: 0.0882 - val_loss: 0.0688 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0713 - accuracy: 0.0441 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0697 - accuracy: 0.0294 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0715 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0687 - accuracy: 0.0735 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0682 - accuracy: 0.0588 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0637 - accuracy: 0.1471 - val_loss: 0.0686 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.09 - 0s 140ms/step - loss: 0.0723 - accuracy: 0.0882 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0663 - accuracy: 0.1029 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0687 - accuracy: 0.1029 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0672 - accuracy: 0.1765 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0669 - accuracy: 0.0882 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0667 - accuracy: 0.1176 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0710 - accuracy: 0.0882 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0701 - accuracy: 0.1029 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0683 - accuracy: 0.1176 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0676 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0698 - accuracy: 0.0441 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0702 - accuracy: 0.1324 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0696 - accuracy: 0.1324 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0668 - accuracy: 0.0882 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0696 - accuracy: 0.0882 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0716 - accuracy: 0.0588 - val_loss: 0.0694 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0673 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0724 - accuracy: 0.0882 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0652 - accuracy: 0.1618 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0691 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0673 - accuracy: 0.0294 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0741 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0702 - accuracy: 0.0441 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0691 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0710 - accuracy: 0.0735 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0698 - accuracy: 0.0588 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0700 - accuracy: 0.1324 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0660 - accuracy: 0.1471 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0687 - accuracy: 0.1176 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0642 - accuracy: 0.1324 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0713 - accuracy: 0.0294 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0663 - accuracy: 0.0294 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0662 - accuracy: 0.1029 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0702 - accuracy: 0.1176 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0707 - accuracy: 0.1176 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0704 - accuracy: 0.0882 - val_loss: 0.0694 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0673 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.0588\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0715 - accuracy: 0.0882 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0733 - accuracy: 0.1176 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0622 - accuracy: 0.1471 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0680 - accuracy: 0.0735 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0712 - accuracy: 0.1029 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0712 - accuracy: 0.0735 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0700 - accuracy: 0.1176 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0683 - accuracy: 0.1176 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0706 - accuracy: 0.0735 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0682 - accuracy: 0.0882 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0651 - accuracy: 0.1324 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.0690 - accuracy: 0.1029 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0675 - accuracy: 0.0000e+00 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0681 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0712 - accuracy: 0.0294 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0666 - accuracy: 0.1176 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0703 - accuracy: 0.0147 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0657 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0700 - accuracy: 0.0294 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0708 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0671 - accuracy: 0.1618 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0744 - accuracy: 0.0294 - val_loss: 0.0681 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0735 - accuracy: 0.0735 - val_loss: 0.0682 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0640 - accuracy: 0.0735 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0697 - accuracy: 0.1176 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0646 - accuracy: 0.0882 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0673 - accuracy: 0.1176 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0694 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0731 - accuracy: 0.0588 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0713 - accuracy: 0.0000e+00 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0679 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0716 - accuracy: 0.1176 - val_loss: 0.0679 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0700 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0684 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0678 - accuracy: 0.0735 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0716 - accuracy: 0.0882 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0684 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0709 - accuracy: 0.0294 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0677 - accuracy: 0.1618 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0702 - accuracy: 0.0882 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0665 - accuracy: 0.1324 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0731 - accuracy: 0.0588 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0706 - accuracy: 0.1176 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0679 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0664 - accuracy: 0.0882 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0738 - accuracy: 0.0735 - val_loss: 0.0687 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0706 - accuracy: 0.1176 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0608 - accuracy: 0.1324 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0729 - accuracy: 0.1029 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0664 - accuracy: 0.0735 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0707 - accuracy: 0.1029 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0665 - accuracy: 0.1618 - val_loss: 0.0691 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0658 - accuracy: 0.0441 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0665 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0669 - accuracy: 0.1029 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0711 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0684 - accuracy: 0.0441 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0716 - accuracy: 0.0735 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0653 - accuracy: 0.1029 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0725 - accuracy: 0.0441 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0682 - accuracy: 0.0735 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0761 - accuracy: 0.0294 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0696 - accuracy: 0.0441 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0745 - accuracy: 0.0588 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0707 - accuracy: 0.1471 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0655 - accuracy: 0.1176 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0707 - accuracy: 0.0588 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0662 - accuracy: 0.0882 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0712 - accuracy: 0.0882 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0679 - accuracy: 0.0882 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0732 - accuracy: 0.0441 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0651 - accuracy: 0.1471 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0684 - accuracy: 0.0735 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0697 - accuracy: 0.1471 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0697 - accuracy: 0.0882 - val_loss: 0.0690 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0672 - accuracy: 0.0735 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0696 - accuracy: 0.0882 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0733 - accuracy: 0.0294 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0680 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0637 - accuracy: 0.1029 - val_loss: 0.0679 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0707 - accuracy: 0.1029 - val_loss: 0.0676 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0690 - accuracy: 0.1324 - val_loss: 0.0674 - val_accuracy: 0.1765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0670 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0682 - accuracy: 0.1176 - val_loss: 0.0672 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0643 - accuracy: 0.1912 - val_loss: 0.0672 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0621 - accuracy: 0.1304 - val_loss: 0.0672 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0656 - accuracy: 0.1304 - val_loss: 0.0675 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0580 - accuracy: 0.1449 - val_loss: 0.0674 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0612 - accuracy: 0.1449 - val_loss: 0.0677 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0644 - accuracy: 0.1449 - val_loss: 0.0678 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0639 - accuracy: 0.1739 - val_loss: 0.0678 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0644 - accuracy: 0.1449 - val_loss: 0.0682 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0602 - accuracy: 0.1159 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0610 - accuracy: 0.2029 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0614 - accuracy: 0.1884 - val_loss: 0.0684 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0603 - accuracy: 0.1884 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0601 - accuracy: 0.1304 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0615 - accuracy: 0.1739 - val_loss: 0.0677 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0653 - accuracy: 0.0870 - val_loss: 0.0680 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0601 - accuracy: 0.1449 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0619 - accuracy: 0.1739 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0612 - accuracy: 0.2174 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0616 - accuracy: 0.1739 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0621 - accuracy: 0.2174 - val_loss: 0.0685 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0604 - accuracy: 0.1884 - val_loss: 0.0683 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0706 - accuracy: 0.0580 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0694 - accuracy: 0.0580 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0699 - accuracy: 0.0580 - val_loss: 0.0686 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0682 - accuracy: 0.0870 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0664 - accuracy: 0.1014 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0705 - accuracy: 0.0580 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0678 - accuracy: 0.0870 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0677 - accuracy: 0.1159 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0689 - accuracy: 0.0290 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0676 - accuracy: 0.1014 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0652 - accuracy: 0.1159 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0690 - accuracy: 0.1159 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0642 - accuracy: 0.1159 - val_loss: 0.0702 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0674 - accuracy: 0.0870 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0652 - accuracy: 0.0870 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0669 - accuracy: 0.1449 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0687 - accuracy: 0.0870 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0662 - accuracy: 0.1159 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0678 - accuracy: 0.1014 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0649 - accuracy: 0.0580 - val_loss: 0.0699 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0677 - accuracy: 0.1304 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0703 - accuracy: 0.1014 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0680 - accuracy: 0.1304 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0656 - accuracy: 0.0725 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0683 - accuracy: 0.0580 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0679 - accuracy: 0.1014 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0684 - accuracy: 0.0580 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0659 - accuracy: 0.1014 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 0.0710 - accuracy: 0.1014 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0714 - accuracy: 0.1159 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0698 - accuracy: 0.0435 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0671 - accuracy: 0.0725 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0705 - accuracy: 0.1159 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0681 - accuracy: 0.0725 - val_loss: 0.0699 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0675 - accuracy: 0.0870 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0709 - accuracy: 0.0435 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0704 - accuracy: 0.1449 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0663 - accuracy: 0.1014 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0697 - accuracy: 0.1014 - val_loss: 0.0688 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0676 - accuracy: 0.1304 - val_loss: 0.0689 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0655 - accuracy: 0.0580 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0683 - accuracy: 0.1594 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0709 - accuracy: 0.0870 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0672 - accuracy: 0.1159 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0718 - accuracy: 0.0145 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0682 - accuracy: 0.1449 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0704 - accuracy: 0.1159 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0728 - accuracy: 0.0725 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0699 - accuracy: 0.0870 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0654 - accuracy: 0.1304 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0641 - accuracy: 0.1159 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0673 - accuracy: 0.0725 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0697 - accuracy: 0.0580 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0706 - accuracy: 0.0725 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0664 - accuracy: 0.1159 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0673 - accuracy: 0.1304 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0629 - accuracy: 0.1739 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0633 - accuracy: 0.1159 - val_loss: 0.0686 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0680 - accuracy: 0.0580 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0664 - accuracy: 0.0870 - val_loss: 0.0682 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0681 - accuracy: 0.0870 - val_loss: 0.0684 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0698 - accuracy: 0.0870 - val_loss: 0.0683 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0680 - accuracy: 0.1159 - val_loss: 0.0685 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0717 - accuracy: 0.0725 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0713 - accuracy: 0.0870 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0662 - accuracy: 0.1304 - val_loss: 0.0682 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0674 - accuracy: 0.1014 - val_loss: 0.0683 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0648 - accuracy: 0.1014 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0685 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0678 - accuracy: 0.1014 - val_loss: 0.0687 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0685 - accuracy: 0.0580 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0667 - accuracy: 0.0725 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0712 - accuracy: 0.1449 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0734 - accuracy: 0.1014 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0673 - accuracy: 0.0725 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0694 - accuracy: 0.1014 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0688 - accuracy: 0.0870 - val_loss: 0.0693 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0703 - accuracy: 0.1159 - val_loss: 0.0696 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0669 - accuracy: 0.1014 - val_loss: 0.0694 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0688 - accuracy: 0.1304 - val_loss: 0.0691 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0667 - accuracy: 0.1304 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0703 - accuracy: 0.0725 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0667 - accuracy: 0.1159 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0707 - accuracy: 0.0725 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0659 - accuracy: 0.1304 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0720 - accuracy: 0.0870 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0678 - accuracy: 0.0870 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0716 - accuracy: 0.1449 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0671 - accuracy: 0.0870 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0710 - accuracy: 0.0735 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0675 - accuracy: 0.1176 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.0693 - accuracy: 0.1324 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0685 - accuracy: 0.0882 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0684 - accuracy: 0.1029 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0665 - accuracy: 0.1029 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0660 - accuracy: 0.1324 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0667 - accuracy: 0.0882 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0693 - accuracy: 0.1912 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0667 - accuracy: 0.1765 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0668 - accuracy: 0.2059 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0706 - accuracy: 0.1029 - val_loss: 0.0694 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0711 - accuracy: 0.0588 - val_loss: 0.0695 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0678 - accuracy: 0.1029 - val_loss: 0.0696 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0672 - accuracy: 0.0735 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0670 - accuracy: 0.1471 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0743 - accuracy: 0.0441 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0652 - accuracy: 0.1471 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0703 - accuracy: 0.0588 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0675 - accuracy: 0.1471 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0731 - accuracy: 0.0735 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0731 - accuracy: 0.0882 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0698 - accuracy: 0.0882 - val_loss: 0.0694 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0688 - accuracy: 0.0882 - val_loss: 0.0689 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0672 - accuracy: 0.1324 - val_loss: 0.0688 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0661 - accuracy: 0.1324 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0692 - accuracy: 0.0588 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0705 - accuracy: 0.0588 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0683 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0697 - accuracy: 0.1176 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0679 - accuracy: 0.1471 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0708 - accuracy: 0.1176 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0680 - accuracy: 0.1471 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0691 - accuracy: 0.0588 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0663 - accuracy: 0.1324 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0683 - accuracy: 0.1324 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0713 - accuracy: 0.0882 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0703 - accuracy: 0.1029 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0663 - accuracy: 0.0588 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0700 - accuracy: 0.1176 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0698 - accuracy: 0.0735 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0725 - accuracy: 0.0588 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0693 - accuracy: 0.1029 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0661 - accuracy: 0.1765 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0702 - accuracy: 0.1029 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0639 - accuracy: 0.1176 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0687 - accuracy: 0.0735 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0712 - accuracy: 0.1176 - val_loss: 0.0693 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0675 - accuracy: 0.0735 - val_loss: 0.0701 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0771 - accuracy: 0.0441 - val_loss: 0.0701 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0690 - accuracy: 0.0588 - val_loss: 0.0702 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0717 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0707 - accuracy: 0.0735 - val_loss: 0.0699 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0698 - accuracy: 0.0588 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0714 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0688 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0681 - accuracy: 0.0735 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0642 - accuracy: 0.1176 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0731 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0668 - accuracy: 0.1324 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0669 - accuracy: 0.1324 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0689 - accuracy: 0.1029 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0672 - accuracy: 0.1912 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0667 - accuracy: 0.1324 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0663 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 0.0720 - accuracy: 0.0882 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0705 - accuracy: 0.1176 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0684 - accuracy: 0.1176 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0671 - accuracy: 0.0735 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0697 - accuracy: 0.0735 - val_loss: 0.0707 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0707 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0703 - accuracy: 0.1618 - val_loss: 0.0708 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0669 - accuracy: 0.0882 - val_loss: 0.0708 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0722 - accuracy: 0.0441 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0669 - accuracy: 0.1029 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0726 - accuracy: 0.0735 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0650 - accuracy: 0.1471 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0672 - accuracy: 0.0441 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0704 - accuracy: 0.0588 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0742 - accuracy: 0.0441 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0703 - accuracy: 0.0735 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0697 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0719 - accuracy: 0.0882 - val_loss: 0.0698 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0703 - accuracy: 0.0294 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0706 - accuracy: 0.1324 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0665 - accuracy: 0.1324 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0692 - accuracy: 0.1029 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0639 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0712 - accuracy: 0.0735 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0664 - accuracy: 0.0294 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0664 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0706 - accuracy: 0.1029 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0710 - accuracy: 0.1176 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0712 - accuracy: 0.0882 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.07 - 0s 142ms/step - loss: 0.0682 - accuracy: 0.0735 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0721 - accuracy: 0.0735 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0742 - accuracy: 0.1029 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0616 - accuracy: 0.1765 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0711 - accuracy: 0.1029 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0715 - accuracy: 0.1029 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0698 - accuracy: 0.1029 - val_loss: 0.0708 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0685 - accuracy: 0.1765 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0712 - accuracy: 0.0735 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0683 - accuracy: 0.1029 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0651 - accuracy: 0.1324 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0693 - accuracy: 0.1176 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0677 - accuracy: 0.0000e+00 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0686 - accuracy: 0.1324 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0711 - accuracy: 0.0588 - val_loss: 0.0696 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0667 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0704 - accuracy: 0.0588 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0662 - accuracy: 0.1029 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0704 - accuracy: 0.0294 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0671 - accuracy: 0.1912 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0746 - accuracy: 0.0441 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0741 - accuracy: 0.0735 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0635 - accuracy: 0.0735 - val_loss: 0.0699 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0698 - accuracy: 0.1029 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0646 - accuracy: 0.1029 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0673 - accuracy: 0.0882 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0699 - accuracy: 0.0882 - val_loss: 0.0699 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0739 - accuracy: 0.0735 - val_loss: 0.0699 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0716 - accuracy: 0.0294 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0696 - accuracy: 0.0882 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0723 - accuracy: 0.1176 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0694 - accuracy: 0.1029 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0703 - accuracy: 0.0588 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0700 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0671 - accuracy: 0.0882 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0708 - accuracy: 0.0882 - val_loss: 0.0694 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0699 - accuracy: 0.0735 - val_loss: 0.0693 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0688 - accuracy: 0.0735 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0709 - accuracy: 0.0588 - val_loss: 0.0696 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0675 - accuracy: 0.1471 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0714 - accuracy: 0.0882 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0664 - accuracy: 0.1324 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0735 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0705 - accuracy: 0.1471 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0682 - accuracy: 0.0882 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0659 - accuracy: 0.0735 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0746 - accuracy: 0.0735 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0710 - accuracy: 0.1324 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0604 - accuracy: 0.1324 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0731 - accuracy: 0.1176 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0671 - accuracy: 0.0588 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0705 - accuracy: 0.0882 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0665 - accuracy: 0.1765 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0653 - accuracy: 0.0735 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0665 - accuracy: 0.1029 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0668 - accuracy: 0.1176 - val_loss: 0.0695 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0709 - accuracy: 0.0735 - val_loss: 0.0694 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0673 - accuracy: 0.0588 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0722 - accuracy: 0.0735 - val_loss: 0.0691 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0651 - accuracy: 0.1324 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0721 - accuracy: 0.0441 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0682 - accuracy: 0.1176 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0767 - accuracy: 0.0441 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0697 - accuracy: 0.0441 - val_loss: 0.0694 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0748 - accuracy: 0.0441 - val_loss: 0.0691 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0708 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0645 - accuracy: 0.1618 - val_loss: 0.0694 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0708 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0655 - accuracy: 0.0882 - val_loss: 0.0691 - val_accuracy: 0.2059\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0679 - accuracy: 0.0882 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0690 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0732 - accuracy: 0.0441 - val_loss: 0.0688 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0651 - accuracy: 0.1176 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0686 - accuracy: 0.0882 - val_loss: 0.0693 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0700 - accuracy: 0.1029 - val_loss: 0.0697 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0669 - accuracy: 0.1471 - val_loss: 0.0690 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0691 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0740 - accuracy: 0.0588 - val_loss: 0.0689 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0693 - accuracy: 0.1176 - val_loss: 0.0687 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0636 - accuracy: 0.1324 - val_loss: 0.0685 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0706 - accuracy: 0.1029 - val_loss: 0.0681 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0685 - accuracy: 0.1471 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0698 - accuracy: 0.1324 - val_loss: 0.0679 - val_accuracy: 0.2059\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0680 - accuracy: 0.1471 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0642 - accuracy: 0.1912 - val_loss: 0.0681 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0618 - accuracy: 0.1449 - val_loss: 0.0684 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0665 - accuracy: 0.1304 - val_loss: 0.0688 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0583 - accuracy: 0.1304 - val_loss: 0.0685 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0618 - accuracy: 0.1449 - val_loss: 0.0687 - val_accuracy: 0.2059\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0651 - accuracy: 0.1449 - val_loss: 0.0687 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0645 - accuracy: 0.1884 - val_loss: 0.0687 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0662 - accuracy: 0.2029 - val_loss: 0.0690 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0606 - accuracy: 0.1449 - val_loss: 0.0688 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.20 - 0s 139ms/step - loss: 0.0609 - accuracy: 0.1884 - val_loss: 0.0689 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0618 - accuracy: 0.1884 - val_loss: 0.0691 - val_accuracy: 0.2059\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0606 - accuracy: 0.2029 - val_loss: 0.0688 - val_accuracy: 0.2059\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0599 - accuracy: 0.1159 - val_loss: 0.0686 - val_accuracy: 0.2059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0618 - accuracy: 0.1304 - val_loss: 0.0687 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0659 - accuracy: 0.1014 - val_loss: 0.0689 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0604 - accuracy: 0.1739 - val_loss: 0.0692 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0633 - accuracy: 0.1739 - val_loss: 0.0693 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0623 - accuracy: 0.2029 - val_loss: 0.0689 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0623 - accuracy: 0.1884 - val_loss: 0.0692 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0628 - accuracy: 0.2029 - val_loss: 0.0695 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0609 - accuracy: 0.1739 - val_loss: 0.0692 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0710 - accuracy: 0.0870 - val_loss: 0.0695 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0687 - accuracy: 0.0725 - val_loss: 0.0696 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0702 - accuracy: 0.0580 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0683 - accuracy: 0.0870 - val_loss: 0.0701 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0667 - accuracy: 0.1304 - val_loss: 0.0706 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0707 - accuracy: 0.0580 - val_loss: 0.0703 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0682 - accuracy: 0.0725 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0679 - accuracy: 0.1739 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0702 - accuracy: 0.0290 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0681 - accuracy: 0.1304 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0654 - accuracy: 0.1159 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0695 - accuracy: 0.1014 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0640 - accuracy: 0.1594 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0673 - accuracy: 0.1014 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0653 - accuracy: 0.1014 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0669 - accuracy: 0.1449 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0697 - accuracy: 0.0725 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0663 - accuracy: 0.1304 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0688 - accuracy: 0.1304 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0661 - accuracy: 0.0435 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0675 - accuracy: 0.1304 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0703 - accuracy: 0.0870 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0690 - accuracy: 0.1159 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0659 - accuracy: 0.0870 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0684 - accuracy: 0.0725 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0681 - accuracy: 0.1304 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0686 - accuracy: 0.0580 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0659 - accuracy: 0.1159 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0716 - accuracy: 0.1014 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0718 - accuracy: 0.1304 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0700 - accuracy: 0.0580 - val_loss: 0.0709 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0674 - accuracy: 0.0870 - val_loss: 0.0708 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0701 - accuracy: 0.1159 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0678 - accuracy: 0.0870 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0686 - accuracy: 0.0870 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0708 - accuracy: 0.0580 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0702 - accuracy: 0.1739 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0667 - accuracy: 0.1014 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0702 - accuracy: 0.1159 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0677 - accuracy: 0.1159 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0658 - accuracy: 0.0870 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0687 - accuracy: 0.1739 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0716 - accuracy: 0.0870 - val_loss: 0.0705 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0666 - accuracy: 0.1304 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0726 - accuracy: 0.0435 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0669 - accuracy: 0.0870 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0687 - accuracy: 0.0870 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0708 - accuracy: 0.0870 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0729 - accuracy: 0.0580 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0706 - accuracy: 0.1014 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0656 - accuracy: 0.1594 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0639 - accuracy: 0.1594 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0665 - accuracy: 0.0435 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0700 - accuracy: 0.0435 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0704 - accuracy: 0.0580 - val_loss: 0.0711 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0663 - accuracy: 0.1304 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0671 - accuracy: 0.1594 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0625 - accuracy: 0.2319 - val_loss: 0.0706 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0631 - accuracy: 0.1304 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0680 - accuracy: 0.0290 - val_loss: 0.0699 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0666 - accuracy: 0.1304 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0681 - accuracy: 0.0870 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0704 - accuracy: 0.0870 - val_loss: 0.0695 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0677 - accuracy: 0.0870 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0718 - accuracy: 0.0725 - val_loss: 0.0701 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0715 - accuracy: 0.0725 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0662 - accuracy: 0.1304 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0678 - accuracy: 0.1159 - val_loss: 0.0697 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0650 - accuracy: 0.1449 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0674 - accuracy: 0.0725 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0680 - accuracy: 0.1159 - val_loss: 0.0697 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0693 - accuracy: 0.0580 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.09 - 0s 146ms/step - loss: 0.0668 - accuracy: 0.0870 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0722 - accuracy: 0.1304 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0738 - accuracy: 0.1304 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0673 - accuracy: 0.0725 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0701 - accuracy: 0.0870 - val_loss: 0.0704 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0691 - accuracy: 0.1159 - val_loss: 0.0700 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0709 - accuracy: 0.1304 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0672 - accuracy: 0.1014 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0690 - accuracy: 0.1159 - val_loss: 0.0699 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0668 - accuracy: 0.1304 - val_loss: 0.0698 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0709 - accuracy: 0.1159 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0673 - accuracy: 0.1449 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0710 - accuracy: 0.0725 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0658 - accuracy: 0.1304 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0716 - accuracy: 0.1159 - val_loss: 0.0700 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0682 - accuracy: 0.1159 - val_loss: 0.0704 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0722 - accuracy: 0.1594 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0666 - accuracy: 0.0725 - val_loss: 0.0712 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0714 - accuracy: 0.1029 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0705 - accuracy: 0.1029 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0680 - accuracy: 0.1471 - val_loss: 0.0711 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0694 - accuracy: 0.1618 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0692 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0685 - accuracy: 0.0735 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0663 - accuracy: 0.1471 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0663 - accuracy: 0.1176 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0667 - accuracy: 0.1029 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0693 - accuracy: 0.1912 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0665 - accuracy: 0.1618 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0670 - accuracy: 0.1765 - val_loss: 0.0701 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0712 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0717 - accuracy: 0.1176 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0680 - accuracy: 0.1029 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0674 - accuracy: 0.0735 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0667 - accuracy: 0.1912 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0744 - accuracy: 0.0588 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0647 - accuracy: 0.1324 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0702 - accuracy: 0.0882 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0739 - accuracy: 0.0882 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0736 - accuracy: 0.0882 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0701 - accuracy: 0.1324 - val_loss: 0.0704 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0689 - accuracy: 0.0735 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 0.0673 - accuracy: 0.1176 - val_loss: 0.0702 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0660 - accuracy: 0.1324 - val_loss: 0.0705 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0692 - accuracy: 0.0588 - val_loss: 0.0709 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0708 - accuracy: 0.0735 - val_loss: 0.0708 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0682 - accuracy: 0.1176 - val_loss: 0.0708 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0700 - accuracy: 0.1176 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0683 - accuracy: 0.1324 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0710 - accuracy: 0.1176 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0680 - accuracy: 0.1324 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0687 - accuracy: 0.0735 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0661 - accuracy: 0.1471 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0671 - accuracy: 0.1029 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0682 - accuracy: 0.1471 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0716 - accuracy: 0.0882 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0707 - accuracy: 0.1176 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0667 - accuracy: 0.0441 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0701 - accuracy: 0.1471 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0700 - accuracy: 0.0882 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0700 - accuracy: 0.1029 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0660 - accuracy: 0.1765 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0699 - accuracy: 0.1029 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0642 - accuracy: 0.1176 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0689 - accuracy: 0.0882 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0720 - accuracy: 0.1324 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0681 - accuracy: 0.0882 - val_loss: 0.0717 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0777 - accuracy: 0.0441 - val_loss: 0.0717 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0696 - accuracy: 0.0735 - val_loss: 0.0718 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0723 - accuracy: 0.0294 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0704 - accuracy: 0.1176 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0701 - accuracy: 0.1176 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0719 - accuracy: 0.0882 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0686 - accuracy: 0.0441 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0685 - accuracy: 0.0441 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0649 - accuracy: 0.1324 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0737 - accuracy: 0.1176 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0670 - accuracy: 0.1765 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0670 - accuracy: 0.1471 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0695 - accuracy: 0.1324 - val_loss: 0.0712 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0674 - accuracy: 0.1912 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0665 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0694 - accuracy: 0.0588 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0665 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0722 - accuracy: 0.1029 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0705 - accuracy: 0.1471 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0695 - accuracy: 0.1029 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0674 - accuracy: 0.0588 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0700 - accuracy: 0.0735 - val_loss: 0.0715 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0716 - accuracy: 0.1471 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0708 - accuracy: 0.1765 - val_loss: 0.0717 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0671 - accuracy: 0.0735 - val_loss: 0.0716 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0699 - accuracy: 0.1029 - val_loss: 0.0717 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0724 - accuracy: 0.0441 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0673 - accuracy: 0.1029 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0733 - accuracy: 0.1029 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0651 - accuracy: 0.1471 - val_loss: 0.0722 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0693 - accuracy: 0.0882 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0672 - accuracy: 0.0294 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0712 - accuracy: 0.0735 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0747 - accuracy: 0.0588 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0697 - accuracy: 0.0735 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0722 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0709 - accuracy: 0.0735 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0712 - accuracy: 0.1324 - val_loss: 0.0715 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0664 - accuracy: 0.1765 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0695 - accuracy: 0.0882 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0642 - accuracy: 0.1765 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0720 - accuracy: 0.0882 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0668 - accuracy: 0.0735 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0671 - accuracy: 0.1176 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0714 - accuracy: 0.0882 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0722 - accuracy: 0.1324 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0717 - accuracy: 0.1029 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0725 - accuracy: 0.0882 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0750 - accuracy: 0.1324 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0624 - accuracy: 0.1618 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0691 - accuracy: 0.0882 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0715 - accuracy: 0.1029 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0718 - accuracy: 0.1029 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0701 - accuracy: 0.1176 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0683 - accuracy: 0.1471 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0713 - accuracy: 0.0882 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0683 - accuracy: 0.1471 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0650 - accuracy: 0.1618 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0694 - accuracy: 0.1176 - val_loss: 0.0716 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0675 - accuracy: 0.0000e+00 - val_loss: 0.0716 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0690 - accuracy: 0.1324 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0714 - accuracy: 0.0588 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0672 - accuracy: 0.1029 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0705 - accuracy: 0.0441 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0665 - accuracy: 0.0735 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0705 - accuracy: 0.0441 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0722 - accuracy: 0.1029 - val_loss: 0.0702 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0673 - accuracy: 0.1912 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0758 - accuracy: 0.0735 - val_loss: 0.0702 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0746 - accuracy: 0.0588 - val_loss: 0.0704 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0634 - accuracy: 0.0588 - val_loss: 0.0707 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0709 - accuracy: 0.1324 - val_loss: 0.0710 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0646 - accuracy: 0.0882 - val_loss: 0.0712 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0668 - accuracy: 0.1324 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0704 - accuracy: 0.1029 - val_loss: 0.0710 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0748 - accuracy: 0.1029 - val_loss: 0.0710 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0719 - accuracy: 0.0588 - val_loss: 0.0706 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0698 - accuracy: 0.1176 - val_loss: 0.0703 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0729 - accuracy: 0.1471 - val_loss: 0.0701 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0705 - accuracy: 0.0882 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0700 - accuracy: 0.0882 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0672 - accuracy: 0.0735 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0717 - accuracy: 0.0735 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0702 - accuracy: 0.0735 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0690 - accuracy: 0.0882 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0716 - accuracy: 0.0588 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0680 - accuracy: 0.1471 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0717 - accuracy: 0.0882 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0662 - accuracy: 0.1912 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0747 - accuracy: 0.0882 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0717 - accuracy: 0.1176 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0688 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0660 - accuracy: 0.0588 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0746 - accuracy: 0.0882 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0711 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0609 - accuracy: 0.1618 - val_loss: 0.0704 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0734 - accuracy: 0.1029 - val_loss: 0.0709 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0667 - accuracy: 0.0882 - val_loss: 0.0715 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0711 - accuracy: 0.1324 - val_loss: 0.0712 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0669 - accuracy: 0.1765 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0650 - accuracy: 0.1471 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0666 - accuracy: 0.1029 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0671 - accuracy: 0.0735 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0673 - accuracy: 0.1324 - val_loss: 0.0707 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0714 - accuracy: 0.0735 - val_loss: 0.0707 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0679 - accuracy: 0.0735 - val_loss: 0.0706 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0716 - accuracy: 0.1029 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0645 - accuracy: 0.1324 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0728 - accuracy: 0.0735 - val_loss: 0.0707 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0684 - accuracy: 0.1029 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0771 - accuracy: 0.0294 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0701 - accuracy: 0.0588 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0754 - accuracy: 0.0441 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0712 - accuracy: 0.1324 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0650 - accuracy: 0.1618 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0712 - accuracy: 0.1029 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0658 - accuracy: 0.1176 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0721 - accuracy: 0.1324 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0687 - accuracy: 0.1029 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0706 - accuracy: 0.0735 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0733 - accuracy: 0.0882 - val_loss: 0.0708 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0648 - accuracy: 0.1324 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0687 - accuracy: 0.0882 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0701 - accuracy: 0.1176 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0673 - accuracy: 0.1324 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0710 - accuracy: 0.1176 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0746 - accuracy: 0.0588 - val_loss: 0.0711 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0699 - accuracy: 0.1176 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0635 - accuracy: 0.1176 - val_loss: 0.0709 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0718 - accuracy: 0.1176 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0693 - accuracy: 0.1471 - val_loss: 0.0703 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0702 - accuracy: 0.1324 - val_loss: 0.0700 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0682 - accuracy: 0.1618 - val_loss: 0.0701 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0645 - accuracy: 0.1618 - val_loss: 0.0702 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0629 - accuracy: 0.1594 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0674 - accuracy: 0.1739 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0583 - accuracy: 0.1594 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0623 - accuracy: 0.1304 - val_loss: 0.0705 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0656 - accuracy: 0.1449 - val_loss: 0.0705 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0657 - accuracy: 0.1304 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0666 - accuracy: 0.1739 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0610 - accuracy: 0.1304 - val_loss: 0.0704 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0620 - accuracy: 0.2174 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0622 - accuracy: 0.1594 - val_loss: 0.0707 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0611 - accuracy: 0.2174 - val_loss: 0.0703 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0599 - accuracy: 0.1594 - val_loss: 0.0698 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0623 - accuracy: 0.1159 - val_loss: 0.0700 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0666 - accuracy: 0.1159 - val_loss: 0.0703 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0614 - accuracy: 0.1739 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0639 - accuracy: 0.1739 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0627 - accuracy: 0.2174 - val_loss: 0.0703 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0630 - accuracy: 0.1739 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0634 - accuracy: 0.2029 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0623 - accuracy: 0.1739 - val_loss: 0.0706 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0712 - accuracy: 0.1159 - val_loss: 0.0707 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0694 - accuracy: 0.0580 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0713 - accuracy: 0.0435 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0693 - accuracy: 0.1014 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0667 - accuracy: 0.1594 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0718 - accuracy: 0.0725 - val_loss: 0.0710 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0688 - accuracy: 0.0725 - val_loss: 0.0711 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0685 - accuracy: 0.1594 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0705 - accuracy: 0.0725 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0679 - accuracy: 0.1304 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0655 - accuracy: 0.1159 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0704 - accuracy: 0.1014 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0643 - accuracy: 0.1884 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0679 - accuracy: 0.1159 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0660 - accuracy: 0.0870 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0673 - accuracy: 0.1304 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0702 - accuracy: 0.0870 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0670 - accuracy: 0.0870 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0687 - accuracy: 0.1594 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0666 - accuracy: 0.0725 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0681 - accuracy: 0.1304 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0707 - accuracy: 0.1159 - val_loss: 0.0722 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0691 - accuracy: 0.1159 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0656 - accuracy: 0.1159 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0688 - accuracy: 0.0870 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0685 - accuracy: 0.1014 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0688 - accuracy: 0.0580 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0668 - accuracy: 0.1014 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0722 - accuracy: 0.1014 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0722 - accuracy: 0.1449 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0703 - accuracy: 0.0580 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0673 - accuracy: 0.0870 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0705 - accuracy: 0.1449 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0683 - accuracy: 0.0870 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0681 - accuracy: 0.0725 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0710 - accuracy: 0.0580 - val_loss: 0.0729 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0701 - accuracy: 0.1449 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0665 - accuracy: 0.1449 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0705 - accuracy: 0.0870 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0677 - accuracy: 0.1449 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0657 - accuracy: 0.0725 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0693 - accuracy: 0.1449 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0726 - accuracy: 0.0870 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0672 - accuracy: 0.1014 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0731 - accuracy: 0.0580 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0668 - accuracy: 0.1014 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0688 - accuracy: 0.1884 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0715 - accuracy: 0.1449 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0735 - accuracy: 0.0580 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0713 - accuracy: 0.1014 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0655 - accuracy: 0.1594 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0640 - accuracy: 0.1449 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0672 - accuracy: 0.0580 - val_loss: 0.0727 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0707 - accuracy: 0.0580 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0707 - accuracy: 0.0870 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0673 - accuracy: 0.1159 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0674 - accuracy: 0.1449 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0632 - accuracy: 0.1884 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0641 - accuracy: 0.1159 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0685 - accuracy: 0.0435 - val_loss: 0.0716 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0669 - accuracy: 0.1014 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0686 - accuracy: 0.1304 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0706 - accuracy: 0.1014 - val_loss: 0.0710 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0683 - accuracy: 0.1159 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0723 - accuracy: 0.0725 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0730 - accuracy: 0.0725 - val_loss: 0.0712 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0662 - accuracy: 0.1159 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0681 - accuracy: 0.1449 - val_loss: 0.0709 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0650 - accuracy: 0.1594 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0678 - accuracy: 0.1014 - val_loss: 0.0709 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0680 - accuracy: 0.0870 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0696 - accuracy: 0.0580 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0671 - accuracy: 0.0870 - val_loss: 0.0709 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 0.0727 - accuracy: 0.1159 - val_loss: 0.0712 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0751 - accuracy: 0.1159 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0672 - accuracy: 0.1159 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0698 - accuracy: 0.1159 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0698 - accuracy: 0.0870 - val_loss: 0.0714 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0716 - accuracy: 0.1304 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0677 - accuracy: 0.1159 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0695 - accuracy: 0.1304 - val_loss: 0.0713 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0675 - accuracy: 0.1159 - val_loss: 0.0710 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0712 - accuracy: 0.0870 - val_loss: 0.0713 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0670 - accuracy: 0.1594 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0720 - accuracy: 0.0870 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0661 - accuracy: 0.1739 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0720 - accuracy: 0.1014 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0693 - accuracy: 0.0870 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0718 - accuracy: 0.1739 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0670 - accuracy: 0.1014 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0721 - accuracy: 0.1324 - val_loss: 0.0731 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0707 - accuracy: 0.1324 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0681 - accuracy: 0.1324 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0694 - accuracy: 0.1765 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0694 - accuracy: 0.1324 - val_loss: 0.0731 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0693 - accuracy: 0.0882 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.17 - 0s 147ms/step - loss: 0.0665 - accuracy: 0.1765 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0666 - accuracy: 0.1324 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0696 - accuracy: 0.2647 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0669 - accuracy: 0.1765 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0674 - accuracy: 0.1618 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0721 - accuracy: 0.0735 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0721 - accuracy: 0.1029 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0682 - accuracy: 0.1176 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0676 - accuracy: 0.1176 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0671 - accuracy: 0.2059 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0754 - accuracy: 0.0441 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0643 - accuracy: 0.1471 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0711 - accuracy: 0.0882 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0683 - accuracy: 0.1324 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0746 - accuracy: 0.0882 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0740 - accuracy: 0.1029 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0712 - accuracy: 0.0882 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0703 - accuracy: 0.1029 - val_loss: 0.0716 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0676 - accuracy: 0.0882 - val_loss: 0.0711 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0660 - accuracy: 0.1471 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0701 - accuracy: 0.0588 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0713 - accuracy: 0.0588 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0708 - accuracy: 0.1324 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0692 - accuracy: 0.1176 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0716 - accuracy: 0.1324 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0679 - accuracy: 0.1471 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0692 - accuracy: 0.0882 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0661 - accuracy: 0.1618 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0670 - accuracy: 0.1029 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0682 - accuracy: 0.1471 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0714 - accuracy: 0.0882 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0708 - accuracy: 0.1176 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0664 - accuracy: 0.0882 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0708 - accuracy: 0.1471 - val_loss: 0.0725 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0704 - accuracy: 0.0735 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0725 - accuracy: 0.0588 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0704 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0657 - accuracy: 0.1765 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0702 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0646 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0691 - accuracy: 0.0588 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0727 - accuracy: 0.1176 - val_loss: 0.0720 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0671 - accuracy: 0.0882 - val_loss: 0.0725 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0785 - accuracy: 0.0441 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0697 - accuracy: 0.1176 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0722 - accuracy: 0.0588 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0710 - accuracy: 0.0882 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0707 - accuracy: 0.1471 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0716 - accuracy: 0.1176 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0685 - accuracy: 0.0735 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0687 - accuracy: 0.0735 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0644 - accuracy: 0.1765 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0743 - accuracy: 0.1176 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0675 - accuracy: 0.1912 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0669 - accuracy: 0.1618 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0700 - accuracy: 0.1324 - val_loss: 0.0718 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0672 - accuracy: 0.1912 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0670 - accuracy: 0.1324 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0686 - accuracy: 0.1324 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0664 - accuracy: 0.1471 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0730 - accuracy: 0.0882 - val_loss: 0.0716 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0712 - accuracy: 0.1176 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0680 - accuracy: 0.0735 - val_loss: 0.0719 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0702 - accuracy: 0.0588 - val_loss: 0.0720 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0713 - accuracy: 0.1029 - val_loss: 0.0720 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0709 - accuracy: 0.1618 - val_loss: 0.0723 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0669 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0705 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0726 - accuracy: 0.0735 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0669 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0736 - accuracy: 0.1029 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0649 - accuracy: 0.1912 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0704 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0679 - accuracy: 0.0588 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0717 - accuracy: 0.1029 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0745 - accuracy: 0.0441 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0704 - accuracy: 0.1176 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0704 - accuracy: 0.0735 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0718 - accuracy: 0.0441 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0722 - accuracy: 0.1324 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0664 - accuracy: 0.1765 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0696 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0640 - accuracy: 0.1471 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0727 - accuracy: 0.1029 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0668 - accuracy: 0.0294 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0672 - accuracy: 0.1471 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0717 - accuracy: 0.1176 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0729 - accuracy: 0.1618 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0720 - accuracy: 0.1029 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0692 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0721 - accuracy: 0.1029 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0748 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0618 - accuracy: 0.1912 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0688 - accuracy: 0.0735 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0717 - accuracy: 0.0735 - val_loss: 0.0732 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0719 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0696 - accuracy: 0.1176 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0683 - accuracy: 0.1471 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0711 - accuracy: 0.0882 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0683 - accuracy: 0.1176 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0647 - accuracy: 0.1618 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0700 - accuracy: 0.1176 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0674 - accuracy: 0.0000e+00 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0683 - accuracy: 0.1176 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0712 - accuracy: 0.0588 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0679 - accuracy: 0.1324 - val_loss: 0.0714 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0710 - accuracy: 0.0441 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0656 - accuracy: 0.0882 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0704 - accuracy: 0.1029 - val_loss: 0.0717 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0724 - accuracy: 0.0882 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0672 - accuracy: 0.2206 - val_loss: 0.0715 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0752 - accuracy: 0.0735 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0762 - accuracy: 0.0735 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0637 - accuracy: 0.0882 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0705 - accuracy: 0.1176 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0647 - accuracy: 0.0882 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0712 - accuracy: 0.0882 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0750 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0727 - accuracy: 0.0441 - val_loss: 0.0723 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0707 - accuracy: 0.1176 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0736 - accuracy: 0.1176 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0699 - accuracy: 0.1029 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0709 - accuracy: 0.1029 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0704 - accuracy: 0.0735 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0672 - accuracy: 0.0882 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0717 - accuracy: 0.0735 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0701 - accuracy: 0.0735 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0688 - accuracy: 0.0882 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0714 - accuracy: 0.0588 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0681 - accuracy: 0.1471 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0663 - accuracy: 0.2059 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0743 - accuracy: 0.1029 - val_loss: 0.0727 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0718 - accuracy: 0.1324 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0691 - accuracy: 0.1029 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0667 - accuracy: 0.0588 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0750 - accuracy: 0.1176 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0716 - accuracy: 0.1471 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0601 - accuracy: 0.1912 - val_loss: 0.0718 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0743 - accuracy: 0.1029 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0672 - accuracy: 0.1176 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0706 - accuracy: 0.1324 - val_loss: 0.0727 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0675 - accuracy: 0.1912 - val_loss: 0.0727 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0652 - accuracy: 0.1765 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0663 - accuracy: 0.1176 - val_loss: 0.0728 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0670 - accuracy: 0.0735 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0676 - accuracy: 0.1324 - val_loss: 0.0724 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0719 - accuracy: 0.1029 - val_loss: 0.0725 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0683 - accuracy: 0.1029 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0729 - accuracy: 0.1029 - val_loss: 0.0720 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0648 - accuracy: 0.1324 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0739 - accuracy: 0.0882 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0689 - accuracy: 0.1029 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0772 - accuracy: 0.0441 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0701 - accuracy: 0.0588 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0758 - accuracy: 0.0588 - val_loss: 0.0718 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0718 - accuracy: 0.1618 - val_loss: 0.0719 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0651 - accuracy: 0.1618 - val_loss: 0.0723 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0720 - accuracy: 0.0882 - val_loss: 0.0719 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0666 - accuracy: 0.0882 - val_loss: 0.0720 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0736 - accuracy: 0.1176 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0693 - accuracy: 0.0735 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0708 - accuracy: 0.0882 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0737 - accuracy: 0.0882 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0650 - accuracy: 0.1471 - val_loss: 0.0721 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0722 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0702 - accuracy: 0.1176 - val_loss: 0.0725 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0706 - accuracy: 0.1471 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0672 - accuracy: 0.1618 - val_loss: 0.0724 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0711 - accuracy: 0.1176 - val_loss: 0.0723 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0753 - accuracy: 0.0294 - val_loss: 0.0722 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0702 - accuracy: 0.1176 - val_loss: 0.0719 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0638 - accuracy: 0.1471 - val_loss: 0.0720 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0722 - accuracy: 0.1029 - val_loss: 0.0716 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0696 - accuracy: 0.1618 - val_loss: 0.0716 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0710 - accuracy: 0.1176 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0687 - accuracy: 0.1765 - val_loss: 0.0715 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0650 - accuracy: 0.1618 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0634 - accuracy: 0.1159 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0678 - accuracy: 0.1449 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0584 - accuracy: 0.1594 - val_loss: 0.0716 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0627 - accuracy: 0.1739 - val_loss: 0.0717 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0659 - accuracy: 0.1014 - val_loss: 0.0717 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0657 - accuracy: 0.1739 - val_loss: 0.0717 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0679 - accuracy: 0.2029 - val_loss: 0.0720 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0617 - accuracy: 0.1159 - val_loss: 0.0716 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0619 - accuracy: 0.2029 - val_loss: 0.0716 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0634 - accuracy: 0.1594 - val_loss: 0.0718 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0614 - accuracy: 0.2319 - val_loss: 0.0714 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0605 - accuracy: 0.1449 - val_loss: 0.0709 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0621 - accuracy: 0.1594 - val_loss: 0.0711 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0665 - accuracy: 0.1304 - val_loss: 0.0713 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0619 - accuracy: 0.2174 - val_loss: 0.0718 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0645 - accuracy: 0.1739 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0638 - accuracy: 0.2609 - val_loss: 0.0715 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0637 - accuracy: 0.1884 - val_loss: 0.0718 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0641 - accuracy: 0.1884 - val_loss: 0.0719 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0620 - accuracy: 0.1739 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0722 - accuracy: 0.1014 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0696 - accuracy: 0.1014 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0723 - accuracy: 0.0580 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0697 - accuracy: 0.1014 - val_loss: 0.0723 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0671 - accuracy: 0.1449 - val_loss: 0.0727 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0725 - accuracy: 0.0870 - val_loss: 0.0726 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0688 - accuracy: 0.1014 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0699 - accuracy: 0.2319 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0710 - accuracy: 0.0580 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0686 - accuracy: 0.1449 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0651 - accuracy: 0.1449 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0701 - accuracy: 0.1014 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0645 - accuracy: 0.1304 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0681 - accuracy: 0.1014 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0661 - accuracy: 0.0870 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0675 - accuracy: 0.1594 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0702 - accuracy: 0.1014 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0663 - accuracy: 0.1159 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0696 - accuracy: 0.1304 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0673 - accuracy: 0.0435 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0679 - accuracy: 0.1594 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0710 - accuracy: 0.1014 - val_loss: 0.0743 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0692 - accuracy: 0.1304 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0658 - accuracy: 0.1014 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0689 - accuracy: 0.1159 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0688 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0693 - accuracy: 0.0725 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0669 - accuracy: 0.1014 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0732 - accuracy: 0.1159 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0726 - accuracy: 0.1304 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 281ms/step - loss: 0.0709 - accuracy: 0.0870 - val_loss: 0.0738 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0673 - accuracy: 0.1014 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0712 - accuracy: 0.1159 - val_loss: 0.0735 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0683 - accuracy: 0.0725 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0688 - accuracy: 0.1304 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0708 - accuracy: 0.0580 - val_loss: 0.0738 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0710 - accuracy: 0.1304 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0668 - accuracy: 0.1304 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0701 - accuracy: 0.1159 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0676 - accuracy: 0.1304 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0658 - accuracy: 0.1014 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0693 - accuracy: 0.1739 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0733 - accuracy: 0.1304 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0673 - accuracy: 0.1449 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0732 - accuracy: 0.0870 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0667 - accuracy: 0.1159 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0694 - accuracy: 0.1594 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0726 - accuracy: 0.1304 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0736 - accuracy: 0.0725 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0718 - accuracy: 0.1304 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0661 - accuracy: 0.1594 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 184ms/step - loss: 0.0637 - accuracy: 0.1594 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0667 - accuracy: 0.0725 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0710 - accuracy: 0.0580 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0713 - accuracy: 0.1014 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0674 - accuracy: 0.1304 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0671 - accuracy: 0.1449 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0627 - accuracy: 0.2029 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0636 - accuracy: 0.1159 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0690 - accuracy: 0.0435 - val_loss: 0.0721 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0672 - accuracy: 0.1449 - val_loss: 0.0717 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0688 - accuracy: 0.1304 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0708 - accuracy: 0.1014 - val_loss: 0.0719 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0685 - accuracy: 0.1594 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0722 - accuracy: 0.0580 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0739 - accuracy: 0.1014 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0672 - accuracy: 0.1594 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0689 - accuracy: 0.1449 - val_loss: 0.0720 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0649 - accuracy: 0.1449 - val_loss: 0.0725 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0683 - accuracy: 0.1014 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0686 - accuracy: 0.1449 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0695 - accuracy: 0.0725 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0672 - accuracy: 0.0870 - val_loss: 0.0723 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0731 - accuracy: 0.1304 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0754 - accuracy: 0.1014 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0677 - accuracy: 0.0870 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0703 - accuracy: 0.1014 - val_loss: 0.0729 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0698 - accuracy: 0.0725 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0721 - accuracy: 0.1159 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0682 - accuracy: 0.1014 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0701 - accuracy: 0.1449 - val_loss: 0.0724 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.0672 - accuracy: 0.1159 - val_loss: 0.0722 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0716 - accuracy: 0.0870 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0674 - accuracy: 0.1449 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.0715 - accuracy: 0.0725 - val_loss: 0.0726 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0657 - accuracy: 0.1594 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0725 - accuracy: 0.1014 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0697 - accuracy: 0.1014 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0722 - accuracy: 0.1884 - val_loss: 0.0731 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0675 - accuracy: 0.0870 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0728 - accuracy: 0.1029 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0711 - accuracy: 0.1324 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0683 - accuracy: 0.1471 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0692 - accuracy: 0.1912 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0696 - accuracy: 0.1471 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0697 - accuracy: 0.1029 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0663 - accuracy: 0.1765 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0670 - accuracy: 0.1324 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0668 - accuracy: 0.1176 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0697 - accuracy: 0.2206 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0674 - accuracy: 0.1912 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0672 - accuracy: 0.2059 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0731 - accuracy: 0.0882 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0724 - accuracy: 0.0882 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0682 - accuracy: 0.0882 - val_loss: 0.0727 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 191ms/step - loss: 0.0680 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0672 - accuracy: 0.2059 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0762 - accuracy: 0.0588 - val_loss: 0.0729 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0647 - accuracy: 0.1324 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0719 - accuracy: 0.0882 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0682 - accuracy: 0.1324 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0754 - accuracy: 0.0882 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0746 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0711 - accuracy: 0.0882 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0710 - accuracy: 0.1176 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0699 - accuracy: 0.1176 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0676 - accuracy: 0.1324 - val_loss: 0.0720 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0656 - accuracy: 0.1471 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0699 - accuracy: 0.0588 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0717 - accuracy: 0.0882 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0688 - accuracy: 0.1324 - val_loss: 0.0727 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0710 - accuracy: 0.1324 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0685 - accuracy: 0.1029 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0721 - accuracy: 0.1618 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0682 - accuracy: 0.1618 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0693 - accuracy: 0.0882 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0668 - accuracy: 0.1765 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0673 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0681 - accuracy: 0.1618 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0718 - accuracy: 0.0882 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0714 - accuracy: 0.1471 - val_loss: 0.0737 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0667 - accuracy: 0.0588 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0713 - accuracy: 0.1618 - val_loss: 0.0735 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0703 - accuracy: 0.0882 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0728 - accuracy: 0.1029 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0705 - accuracy: 0.1029 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0663 - accuracy: 0.1765 - val_loss: 0.0735 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0706 - accuracy: 0.1029 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0647 - accuracy: 0.1912 - val_loss: 0.0734 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0727 - accuracy: 0.1324 - val_loss: 0.0728 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0679 - accuracy: 0.1029 - val_loss: 0.0733 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0793 - accuracy: 0.0588 - val_loss: 0.0732 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0705 - accuracy: 0.1029 - val_loss: 0.0732 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0728 - accuracy: 0.0882 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0715 - accuracy: 0.0882 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0704 - accuracy: 0.1471 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0718 - accuracy: 0.0882 - val_loss: 0.0732 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0689 - accuracy: 0.0882 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0695 - accuracy: 0.0735 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0649 - accuracy: 0.1471 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 184ms/step - loss: 0.0747 - accuracy: 0.1176 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0668 - accuracy: 0.2059 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0674 - accuracy: 0.1618 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0704 - accuracy: 0.1471 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0674 - accuracy: 0.2353 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0672 - accuracy: 0.1324 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0695 - accuracy: 0.1029 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0666 - accuracy: 0.1618 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0733 - accuracy: 0.1029 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0718 - accuracy: 0.1471 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0704 - accuracy: 0.1324 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0685 - accuracy: 0.0882 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0709 - accuracy: 0.0882 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0723 - accuracy: 0.1324 - val_loss: 0.0736 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0722 - accuracy: 0.1765 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0675 - accuracy: 0.1029 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0717 - accuracy: 0.1029 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0736 - accuracy: 0.0441 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0671 - accuracy: 0.1176 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0740 - accuracy: 0.1176 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0654 - accuracy: 0.1765 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0706 - accuracy: 0.0735 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0681 - accuracy: 0.0735 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0724 - accuracy: 0.1029 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0750 - accuracy: 0.0441 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0705 - accuracy: 0.0882 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0706 - accuracy: 0.0882 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0723 - accuracy: 0.1176 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0714 - accuracy: 0.1029 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0725 - accuracy: 0.1029 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0667 - accuracy: 0.1765 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0695 - accuracy: 0.1029 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0641 - accuracy: 0.2206 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0728 - accuracy: 0.1176 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0664 - accuracy: 0.1029 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0667 - accuracy: 0.1471 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0721 - accuracy: 0.1029 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0731 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0723 - accuracy: 0.0882 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0698 - accuracy: 0.0882 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0726 - accuracy: 0.0588 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0753 - accuracy: 0.1176 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0624 - accuracy: 0.1471 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0687 - accuracy: 0.1029 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0719 - accuracy: 0.0882 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0722 - accuracy: 0.1176 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0697 - accuracy: 0.1176 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0682 - accuracy: 0.1618 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0712 - accuracy: 0.1324 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0686 - accuracy: 0.1471 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0649 - accuracy: 0.1912 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0705 - accuracy: 0.1176 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0680 - accuracy: 0.0000e+00 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0688 - accuracy: 0.1324 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0720 - accuracy: 0.0735 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0678 - accuracy: 0.1176 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0715 - accuracy: 0.0588 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0671 - accuracy: 0.0882 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0711 - accuracy: 0.1471 - val_loss: 0.0726 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 183ms/step - loss: 0.0727 - accuracy: 0.0882 - val_loss: 0.0725 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0673 - accuracy: 0.1912 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0756 - accuracy: 0.0735 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0762 - accuracy: 0.1176 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0636 - accuracy: 0.0735 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0711 - accuracy: 0.1176 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0654 - accuracy: 0.1029 - val_loss: 0.0734 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0669 - accuracy: 0.1324 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0717 - accuracy: 0.0882 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0755 - accuracy: 0.1176 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0729 - accuracy: 0.0147 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0711 - accuracy: 0.1176 - val_loss: 0.0727 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0745 - accuracy: 0.1471 - val_loss: 0.0725 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0706 - accuracy: 0.1176 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0712 - accuracy: 0.1176 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0708 - accuracy: 0.0735 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0678 - accuracy: 0.0882 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0725 - accuracy: 0.0882 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0703 - accuracy: 0.0735 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0698 - accuracy: 0.0441 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0723 - accuracy: 0.0735 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0693 - accuracy: 0.1324 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0729 - accuracy: 0.0882 - val_loss: 0.0735 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0666 - accuracy: 0.1912 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0761 - accuracy: 0.0882 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0724 - accuracy: 0.1176 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0690 - accuracy: 0.1471 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0669 - accuracy: 0.0441 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0753 - accuracy: 0.1029 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0719 - accuracy: 0.1471 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0605 - accuracy: 0.1912 - val_loss: 0.0725 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0740 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0668 - accuracy: 0.1471 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0711 - accuracy: 0.1324 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0676 - accuracy: 0.1765 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0653 - accuracy: 0.2059 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0665 - accuracy: 0.1176 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 183ms/step - loss: 0.0670 - accuracy: 0.0735 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0674 - accuracy: 0.1618 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0722 - accuracy: 0.0882 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0683 - accuracy: 0.0735 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0650 - accuracy: 0.1765 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0740 - accuracy: 0.1176 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0689 - accuracy: 0.1324 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0773 - accuracy: 0.0441 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0702 - accuracy: 0.0588 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0766 - accuracy: 0.0735 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0718 - accuracy: 0.1324 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0652 - accuracy: 0.1912 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 182ms/step - loss: 0.0722 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0670 - accuracy: 0.1324 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0738 - accuracy: 0.1324 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0683 - accuracy: 0.0588 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0713 - accuracy: 0.1029 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0742 - accuracy: 0.1029 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0644 - accuracy: 0.1765 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0697 - accuracy: 0.1029 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0706 - accuracy: 0.1324 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0704 - accuracy: 0.1324 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0676 - accuracy: 0.1029 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0710 - accuracy: 0.1176 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0760 - accuracy: 0.0441 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0701 - accuracy: 0.1029 - val_loss: 0.0728 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0641 - accuracy: 0.1324 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0722 - accuracy: 0.0882 - val_loss: 0.0724 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0698 - accuracy: 0.1471 - val_loss: 0.0723 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0709 - accuracy: 0.1324 - val_loss: 0.0721 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0680 - accuracy: 0.1618 - val_loss: 0.0722 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0643 - accuracy: 0.2059 - val_loss: 0.0725 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0640 - accuracy: 0.1304 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0693 - accuracy: 0.1739 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0588 - accuracy: 0.1594 - val_loss: 0.0725 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0629 - accuracy: 0.1594 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0668 - accuracy: 0.1449 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0666 - accuracy: 0.1884 - val_loss: 0.0724 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0688 - accuracy: 0.2174 - val_loss: 0.0726 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 0.0622 - accuracy: 0.1304 - val_loss: 0.0723 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0624 - accuracy: 0.2029 - val_loss: 0.0723 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0634 - accuracy: 0.2174 - val_loss: 0.0724 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0620 - accuracy: 0.2464 - val_loss: 0.0721 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0610 - accuracy: 0.1449 - val_loss: 0.0718 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0626 - accuracy: 0.1159 - val_loss: 0.0719 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0670 - accuracy: 0.1304 - val_loss: 0.0724 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0621 - accuracy: 0.1594 - val_loss: 0.0729 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0645 - accuracy: 0.1884 - val_loss: 0.0730 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0646 - accuracy: 0.2174 - val_loss: 0.0726 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0644 - accuracy: 0.2029 - val_loss: 0.0728 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0647 - accuracy: 0.2464 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0625 - accuracy: 0.1884 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0727 - accuracy: 0.0870 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0697 - accuracy: 0.0870 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0727 - accuracy: 0.0580 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 0.0696 - accuracy: 0.1304 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0674 - accuracy: 0.1159 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0731 - accuracy: 0.0725 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0694 - accuracy: 0.1014 - val_loss: 0.0737 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0694 - accuracy: 0.2174 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0718 - accuracy: 0.0580 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0686 - accuracy: 0.1159 - val_loss: 0.0740 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0655 - accuracy: 0.1884 - val_loss: 0.0740 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0706 - accuracy: 0.1159 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0645 - accuracy: 0.1159 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0685 - accuracy: 0.1014 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0667 - accuracy: 0.1159 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0679 - accuracy: 0.1739 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0711 - accuracy: 0.1014 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0669 - accuracy: 0.1014 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0696 - accuracy: 0.1884 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0683 - accuracy: 0.0580 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0683 - accuracy: 0.1449 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0711 - accuracy: 0.1014 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0700 - accuracy: 0.1159 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0657 - accuracy: 0.1159 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0698 - accuracy: 0.1014 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0699 - accuracy: 0.1304 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0691 - accuracy: 0.0870 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0669 - accuracy: 0.0870 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0739 - accuracy: 0.1014 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0734 - accuracy: 0.1739 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0714 - accuracy: 0.0580 - val_loss: 0.0740 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0677 - accuracy: 0.1014 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0718 - accuracy: 0.1159 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0689 - accuracy: 0.0870 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0693 - accuracy: 0.1304 - val_loss: 0.0737 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0716 - accuracy: 0.0580 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0708 - accuracy: 0.1449 - val_loss: 0.0739 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0668 - accuracy: 0.1449 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0707 - accuracy: 0.1594 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0681 - accuracy: 0.1159 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0663 - accuracy: 0.0870 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0703 - accuracy: 0.1594 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0740 - accuracy: 0.1304 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0681 - accuracy: 0.1159 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0735 - accuracy: 0.0580 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0673 - accuracy: 0.1159 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0699 - accuracy: 0.1449 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0730 - accuracy: 0.1304 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0745 - accuracy: 0.0580 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0715 - accuracy: 0.1304 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 0.0665 - accuracy: 0.1594 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0643 - accuracy: 0.1594 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0675 - accuracy: 0.0580 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0718 - accuracy: 0.0725 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0711 - accuracy: 0.1014 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0675 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0676 - accuracy: 0.1449 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0632 - accuracy: 0.1739 - val_loss: 0.0740 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0635 - accuracy: 0.1304 - val_loss: 0.0737 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0693 - accuracy: 0.0435 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0672 - accuracy: 0.1159 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0693 - accuracy: 0.1304 - val_loss: 0.0733 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0713 - accuracy: 0.0870 - val_loss: 0.0732 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0686 - accuracy: 0.1594 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0730 - accuracy: 0.0870 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0742 - accuracy: 0.0725 - val_loss: 0.0735 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0668 - accuracy: 0.1449 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0691 - accuracy: 0.1304 - val_loss: 0.0734 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0656 - accuracy: 0.1304 - val_loss: 0.0737 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0689 - accuracy: 0.0290 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0691 - accuracy: 0.1449 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0703 - accuracy: 0.0725 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0679 - accuracy: 0.1014 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0741 - accuracy: 0.1159 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0756 - accuracy: 0.1304 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0679 - accuracy: 0.1014 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0697 - accuracy: 0.1159 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0708 - accuracy: 0.0870 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0720 - accuracy: 0.1449 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0680 - accuracy: 0.1159 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0699 - accuracy: 0.1449 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0673 - accuracy: 0.1449 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0722 - accuracy: 0.1014 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0680 - accuracy: 0.1449 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0721 - accuracy: 0.0725 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0663 - accuracy: 0.1739 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0724 - accuracy: 0.1014 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0696 - accuracy: 0.1304 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0729 - accuracy: 0.1884 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0672 - accuracy: 0.1159 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0731 - accuracy: 0.1029 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0713 - accuracy: 0.1471 - val_loss: 0.0742 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0687 - accuracy: 0.1618 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0692 - accuracy: 0.1912 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 181ms/step - loss: 0.0700 - accuracy: 0.1324 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0697 - accuracy: 0.1029 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0665 - accuracy: 0.1618 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0671 - accuracy: 0.1324 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0669 - accuracy: 0.1324 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0704 - accuracy: 0.2206 - val_loss: 0.0740 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0674 - accuracy: 0.1765 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 185ms/step - loss: 0.0674 - accuracy: 0.1912 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0740 - accuracy: 0.1176 - val_loss: 0.0736 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0735 - accuracy: 0.0882 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0692 - accuracy: 0.1029 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0679 - accuracy: 0.1176 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0675 - accuracy: 0.2206 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0765 - accuracy: 0.0882 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0649 - accuracy: 0.1618 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0718 - accuracy: 0.0882 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0682 - accuracy: 0.1618 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0757 - accuracy: 0.1324 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0748 - accuracy: 0.1471 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0716 - accuracy: 0.1029 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0710 - accuracy: 0.1471 - val_loss: 0.0734 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0706 - accuracy: 0.1176 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0677 - accuracy: 0.1324 - val_loss: 0.0731 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0658 - accuracy: 0.1765 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0700 - accuracy: 0.0588 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0738 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0693 - accuracy: 0.1029 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0716 - accuracy: 0.1176 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0723 - accuracy: 0.1324 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0680 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0668 - accuracy: 0.1618 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0671 - accuracy: 0.1176 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0687 - accuracy: 0.1324 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0718 - accuracy: 0.1324 - val_loss: 0.0750 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0669 - accuracy: 0.1176 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0714 - accuracy: 0.1618 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0706 - accuracy: 0.1029 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0732 - accuracy: 0.0882 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0711 - accuracy: 0.1176 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0665 - accuracy: 0.1618 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0709 - accuracy: 0.1324 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0647 - accuracy: 0.1471 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0703 - accuracy: 0.0588 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0737 - accuracy: 0.1176 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0685 - accuracy: 0.0882 - val_loss: 0.0743 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0795 - accuracy: 0.0588 - val_loss: 0.0742 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0703 - accuracy: 0.1324 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0732 - accuracy: 0.0441 - val_loss: 0.0742 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0742 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0706 - accuracy: 0.1471 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0724 - accuracy: 0.0882 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0691 - accuracy: 0.0882 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0743 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0649 - accuracy: 0.1618 - val_loss: 0.0743 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0756 - accuracy: 0.1029 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0678 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0677 - accuracy: 0.1912 - val_loss: 0.0745 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0706 - accuracy: 0.1471 - val_loss: 0.0743 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0686 - accuracy: 0.2059 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0673 - accuracy: 0.1324 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0698 - accuracy: 0.0882 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0670 - accuracy: 0.1471 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0743 - accuracy: 0.0882 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0726 - accuracy: 0.1765 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0710 - accuracy: 0.1029 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0690 - accuracy: 0.0588 - val_loss: 0.0741 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0706 - accuracy: 0.0735 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0730 - accuracy: 0.1471 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0729 - accuracy: 0.1176 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0680 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.0721 - accuracy: 0.0882 - val_loss: 0.0746 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0738 - accuracy: 0.0588 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0672 - accuracy: 0.1765 - val_loss: 0.0750 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0747 - accuracy: 0.1029 - val_loss: 0.0751 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0661 - accuracy: 0.1471 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0716 - accuracy: 0.1029 - val_loss: 0.0754 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0688 - accuracy: 0.0441 - val_loss: 0.0756 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0723 - accuracy: 0.0735 - val_loss: 0.0758 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0763 - accuracy: 0.0441 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0709 - accuracy: 0.1324 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0715 - accuracy: 0.0735 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0731 - accuracy: 0.1324 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0724 - accuracy: 0.0588 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0735 - accuracy: 0.1471 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0671 - accuracy: 0.1618 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0702 - accuracy: 0.1471 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0649 - accuracy: 0.2059 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0740 - accuracy: 0.1324 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0671 - accuracy: 0.0882 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0673 - accuracy: 0.1471 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0726 - accuracy: 0.1324 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0744 - accuracy: 0.1618 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0735 - accuracy: 0.0882 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0709 - accuracy: 0.1176 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0726 - accuracy: 0.0735 - val_loss: 0.0757 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0759 - accuracy: 0.0882 - val_loss: 0.0753 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0624 - accuracy: 0.1912 - val_loss: 0.0753 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0699 - accuracy: 0.1176 - val_loss: 0.0753 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0723 - accuracy: 0.1029 - val_loss: 0.0752 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0730 - accuracy: 0.1029 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0689 - accuracy: 0.1471 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0719 - accuracy: 0.0882 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0692 - accuracy: 0.1324 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0651 - accuracy: 0.1618 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0709 - accuracy: 0.1176 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0676 - accuracy: 0.0294 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0692 - accuracy: 0.1471 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0714 - accuracy: 0.0588 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0681 - accuracy: 0.1324 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0717 - accuracy: 0.0735 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0674 - accuracy: 0.0882 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 0.0717 - accuracy: 0.1176 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0736 - accuracy: 0.1029 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0678 - accuracy: 0.2059 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0760 - accuracy: 0.0882 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0775 - accuracy: 0.0735 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0638 - accuracy: 0.1029 - val_loss: 0.0742 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0716 - accuracy: 0.1324 - val_loss: 0.0745 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0655 - accuracy: 0.1324 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0671 - accuracy: 0.1176 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0720 - accuracy: 0.0882 - val_loss: 0.0746 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0768 - accuracy: 0.1029 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0734 - accuracy: 0.0735 - val_loss: 0.0739 - val_accuracy: 0.1765\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0715 - accuracy: 0.1471 - val_loss: 0.0736 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0748 - accuracy: 0.1324 - val_loss: 0.0734 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0704 - accuracy: 0.1176 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0719 - accuracy: 0.1029 - val_loss: 0.0740 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0708 - accuracy: 0.1029 - val_loss: 0.0740 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0676 - accuracy: 0.1176 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0703 - accuracy: 0.0882 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0699 - accuracy: 0.0735 - val_loss: 0.0743 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0724 - accuracy: 0.0735 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0689 - accuracy: 0.1618 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0740 - accuracy: 0.1029 - val_loss: 0.0750 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0668 - accuracy: 0.2059 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0759 - accuracy: 0.1176 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0731 - accuracy: 0.1471 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0691 - accuracy: 0.1471 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0672 - accuracy: 0.0588 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0755 - accuracy: 0.1029 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0728 - accuracy: 0.1618 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0604 - accuracy: 0.1912 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0748 - accuracy: 0.0882 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0674 - accuracy: 0.1324 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0717 - accuracy: 0.1324 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0683 - accuracy: 0.1912 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0655 - accuracy: 0.2206 - val_loss: 0.0750 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0675 - accuracy: 0.1324 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0673 - accuracy: 0.0882 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0681 - accuracy: 0.1471 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 187ms/step - loss: 0.0689 - accuracy: 0.0735 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0729 - accuracy: 0.1324 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0649 - accuracy: 0.1471 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0746 - accuracy: 0.0735 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0686 - accuracy: 0.1176 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0776 - accuracy: 0.0588 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0707 - accuracy: 0.0588 - val_loss: 0.0740 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0775 - accuracy: 0.0882 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0722 - accuracy: 0.1029 - val_loss: 0.0736 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0650 - accuracy: 0.1912 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0725 - accuracy: 0.1029 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0668 - accuracy: 0.1029 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0740 - accuracy: 0.1618 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0690 - accuracy: 0.0735 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0714 - accuracy: 0.1029 - val_loss: 0.0735 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0744 - accuracy: 0.1029 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 192ms/step - loss: 0.0648 - accuracy: 0.1912 - val_loss: 0.0732 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0707 - accuracy: 0.1765 - val_loss: 0.0738 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0708 - accuracy: 0.1471 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0678 - accuracy: 0.1324 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0710 - accuracy: 0.1324 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0765 - accuracy: 0.0735 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0702 - accuracy: 0.1324 - val_loss: 0.0734 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0643 - accuracy: 0.1618 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0723 - accuracy: 0.1029 - val_loss: 0.0730 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0698 - accuracy: 0.1324 - val_loss: 0.0727 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0707 - accuracy: 0.1324 - val_loss: 0.0725 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0682 - accuracy: 0.1618 - val_loss: 0.0728 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0643 - accuracy: 0.1618 - val_loss: 0.0728 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0641 - accuracy: 0.1594 - val_loss: 0.0730 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0698 - accuracy: 0.1594 - val_loss: 0.0734 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0586 - accuracy: 0.1884 - val_loss: 0.0733 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0640 - accuracy: 0.2029 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0666 - accuracy: 0.1449 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.0668 - accuracy: 0.1884 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0698 - accuracy: 0.1739 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0626 - accuracy: 0.1304 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0623 - accuracy: 0.2029 - val_loss: 0.0732 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0640 - accuracy: 0.2319 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0619 - accuracy: 0.2464 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0607 - accuracy: 0.1884 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0625 - accuracy: 0.1739 - val_loss: 0.0729 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0676 - accuracy: 0.1449 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0628 - accuracy: 0.1884 - val_loss: 0.0734 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0656 - accuracy: 0.1739 - val_loss: 0.0733 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0648 - accuracy: 0.2174 - val_loss: 0.0731 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0645 - accuracy: 0.1884 - val_loss: 0.0732 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0648 - accuracy: 0.2319 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0631 - accuracy: 0.1884 - val_loss: 0.0735 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 0.0730 - accuracy: 0.1014 - val_loss: 0.0736 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0693 - accuracy: 0.0870 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0730 - accuracy: 0.0580 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0698 - accuracy: 0.1014 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0677 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0734 - accuracy: 0.0870 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0699 - accuracy: 0.1304 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0706 - accuracy: 0.2029 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0719 - accuracy: 0.0580 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0685 - accuracy: 0.1449 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 1s 296ms/step - loss: 0.0659 - accuracy: 0.1594 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0708 - accuracy: 0.1304 - val_loss: 0.0753 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0648 - accuracy: 0.1739 - val_loss: 0.0753 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0692 - accuracy: 0.1014 - val_loss: 0.0751 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0666 - accuracy: 0.0870 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0680 - accuracy: 0.1884 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0715 - accuracy: 0.0580 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0668 - accuracy: 0.1159 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0702 - accuracy: 0.1449 - val_loss: 0.0745 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0679 - accuracy: 0.1014 - val_loss: 0.0746 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0684 - accuracy: 0.1304 - val_loss: 0.0749 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0715 - accuracy: 0.1304 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0701 - accuracy: 0.1304 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0661 - accuracy: 0.1304 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0696 - accuracy: 0.1014 - val_loss: 0.0751 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0699 - accuracy: 0.1594 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0694 - accuracy: 0.0725 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0674 - accuracy: 0.1159 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0747 - accuracy: 0.0870 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0738 - accuracy: 0.1159 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0716 - accuracy: 0.1014 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0674 - accuracy: 0.1159 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0720 - accuracy: 0.1014 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0685 - accuracy: 0.1159 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 177ms/step - loss: 0.0694 - accuracy: 0.1304 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0714 - accuracy: 0.0580 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0711 - accuracy: 0.1304 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0670 - accuracy: 0.1739 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0713 - accuracy: 0.1594 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0687 - accuracy: 0.1449 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0669 - accuracy: 0.1159 - val_loss: 0.0740 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0700 - accuracy: 0.1594 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0745 - accuracy: 0.1159 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0686 - accuracy: 0.1159 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0740 - accuracy: 0.0725 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0673 - accuracy: 0.1304 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0695 - accuracy: 0.1594 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0740 - accuracy: 0.1449 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 184ms/step - loss: 0.0744 - accuracy: 0.0725 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0720 - accuracy: 0.1739 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0670 - accuracy: 0.1594 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0643 - accuracy: 0.2174 - val_loss: 0.0749 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 175ms/step - loss: 0.0670 - accuracy: 0.0870 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0721 - accuracy: 0.0870 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0712 - accuracy: 0.1014 - val_loss: 0.0753 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0686 - accuracy: 0.1449 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0675 - accuracy: 0.1739 - val_loss: 0.0753 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0636 - accuracy: 0.2029 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0642 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0698 - accuracy: 0.0290 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0672 - accuracy: 0.1304 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0701 - accuracy: 0.1449 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0719 - accuracy: 0.0870 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0692 - accuracy: 0.1594 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0728 - accuracy: 0.0725 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0746 - accuracy: 0.0870 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0673 - accuracy: 0.1594 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0699 - accuracy: 0.1594 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0655 - accuracy: 0.1594 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0690 - accuracy: 0.0725 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0689 - accuracy: 0.1304 - val_loss: 0.0739 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0713 - accuracy: 0.0580 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0684 - accuracy: 0.1014 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0742 - accuracy: 0.1449 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0766 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0678 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0704 - accuracy: 0.1159 - val_loss: 0.0746 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0709 - accuracy: 0.0870 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0724 - accuracy: 0.1304 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0686 - accuracy: 0.1159 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0700 - accuracy: 0.1594 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0675 - accuracy: 0.1304 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.0723 - accuracy: 0.0870 - val_loss: 0.0742 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0681 - accuracy: 0.1594 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0723 - accuracy: 0.0725 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0664 - accuracy: 0.1884 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0728 - accuracy: 0.1014 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0706 - accuracy: 0.1304 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0729 - accuracy: 0.1884 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0678 - accuracy: 0.0725 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0730 - accuracy: 0.1029 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0720 - accuracy: 0.1618 - val_loss: 0.0751 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0685 - accuracy: 0.1471 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0697 - accuracy: 0.1765 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0703 - accuracy: 0.1176 - val_loss: 0.0752 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0695 - accuracy: 0.0882 - val_loss: 0.0751 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0661 - accuracy: 0.1765 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 187ms/step - loss: 0.0669 - accuracy: 0.1324 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0667 - accuracy: 0.1029 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0705 - accuracy: 0.2059 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0674 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0669 - accuracy: 0.2353 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0744 - accuracy: 0.1324 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0735 - accuracy: 0.1176 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0688 - accuracy: 0.1029 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0682 - accuracy: 0.1029 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0678 - accuracy: 0.2206 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0766 - accuracy: 0.0882 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 185ms/step - loss: 0.0648 - accuracy: 0.1324 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0725 - accuracy: 0.1029 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0690 - accuracy: 0.1176 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0763 - accuracy: 0.1176 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0755 - accuracy: 0.1176 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0724 - accuracy: 0.1029 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0719 - accuracy: 0.1176 - val_loss: 0.0743 - val_accuracy: 0.1471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0705 - accuracy: 0.1176 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0675 - accuracy: 0.1324 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0660 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0707 - accuracy: 0.0735 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0724 - accuracy: 0.0735 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0694 - accuracy: 0.0882 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0720 - accuracy: 0.1324 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0722 - accuracy: 0.1618 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0683 - accuracy: 0.1765 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0701 - accuracy: 0.0882 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0675 - accuracy: 0.1912 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0669 - accuracy: 0.1176 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0692 - accuracy: 0.1324 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0719 - accuracy: 0.1324 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0672 - accuracy: 0.1176 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0715 - accuracy: 0.1765 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0711 - accuracy: 0.1029 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0736 - accuracy: 0.0882 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0714 - accuracy: 0.1176 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0661 - accuracy: 0.2059 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0708 - accuracy: 0.1324 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0644 - accuracy: 0.1324 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0704 - accuracy: 0.0882 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0743 - accuracy: 0.1176 - val_loss: 0.0737 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0686 - accuracy: 0.0882 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0801 - accuracy: 0.0735 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0713 - accuracy: 0.1176 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0737 - accuracy: 0.0735 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0728 - accuracy: 0.1029 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0715 - accuracy: 0.1471 - val_loss: 0.0739 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0722 - accuracy: 0.1324 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0688 - accuracy: 0.1176 - val_loss: 0.0742 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0696 - accuracy: 0.0735 - val_loss: 0.0743 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0649 - accuracy: 0.1618 - val_loss: 0.0743 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0759 - accuracy: 0.1176 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0679 - accuracy: 0.1912 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0670 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0706 - accuracy: 0.1471 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0679 - accuracy: 0.2206 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0674 - accuracy: 0.1471 - val_loss: 0.0739 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0695 - accuracy: 0.1176 - val_loss: 0.0738 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0667 - accuracy: 0.1618 - val_loss: 0.0737 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0745 - accuracy: 0.0882 - val_loss: 0.0741 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0724 - accuracy: 0.1471 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0712 - accuracy: 0.1471 - val_loss: 0.0744 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0688 - accuracy: 0.0588 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0711 - accuracy: 0.0735 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0729 - accuracy: 0.1176 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0731 - accuracy: 0.1471 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0677 - accuracy: 0.1324 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0715 - accuracy: 0.1176 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 191ms/step - loss: 0.0740 - accuracy: 0.0588 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0679 - accuracy: 0.1324 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0753 - accuracy: 0.1029 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0655 - accuracy: 0.2059 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0714 - accuracy: 0.1029 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0689 - accuracy: 0.0441 - val_loss: 0.0753 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0731 - accuracy: 0.1029 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0756 - accuracy: 0.0588 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0710 - accuracy: 0.1324 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0713 - accuracy: 0.1176 - val_loss: 0.0749 - val_accuracy: 0.0882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0736 - accuracy: 0.0882 - val_loss: 0.0743 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0726 - accuracy: 0.0882 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0738 - accuracy: 0.1471 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0674 - accuracy: 0.1912 - val_loss: 0.0749 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0705 - accuracy: 0.1029 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0651 - accuracy: 0.2059 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0747 - accuracy: 0.0882 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0666 - accuracy: 0.1324 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0676 - accuracy: 0.1618 - val_loss: 0.0753 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0732 - accuracy: 0.0882 - val_loss: 0.0755 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0746 - accuracy: 0.1618 - val_loss: 0.0756 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0733 - accuracy: 0.1029 - val_loss: 0.0755 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0711 - accuracy: 0.0882 - val_loss: 0.0754 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0733 - accuracy: 0.1176 - val_loss: 0.0759 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0763 - accuracy: 0.1029 - val_loss: 0.0756 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0634 - accuracy: 0.1912 - val_loss: 0.0758 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0698 - accuracy: 0.1324 - val_loss: 0.0758 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0724 - accuracy: 0.1029 - val_loss: 0.0758 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0729 - accuracy: 0.1029 - val_loss: 0.0753 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0703 - accuracy: 0.1324 - val_loss: 0.0752 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0689 - accuracy: 0.1765 - val_loss: 0.0751 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0725 - accuracy: 0.1324 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0693 - accuracy: 0.1029 - val_loss: 0.0749 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0657 - accuracy: 0.1618 - val_loss: 0.0751 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0715 - accuracy: 0.1029 - val_loss: 0.0750 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0682 - accuracy: 0.0441 - val_loss: 0.0751 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0696 - accuracy: 0.1471 - val_loss: 0.0748 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0721 - accuracy: 0.0735 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0688 - accuracy: 0.1029 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0719 - accuracy: 0.0441 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0675 - accuracy: 0.0882 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0713 - accuracy: 0.1176 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0736 - accuracy: 0.1029 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0678 - accuracy: 0.1912 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0760 - accuracy: 0.0882 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0778 - accuracy: 0.1324 - val_loss: 0.0746 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0641 - accuracy: 0.0882 - val_loss: 0.0750 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0719 - accuracy: 0.1176 - val_loss: 0.0754 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0655 - accuracy: 0.1618 - val_loss: 0.0755 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0673 - accuracy: 0.1029 - val_loss: 0.0754 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0727 - accuracy: 0.1029 - val_loss: 0.0753 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0771 - accuracy: 0.1029 - val_loss: 0.0752 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0744 - accuracy: 0.0588 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.0721 - accuracy: 0.1618 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0753 - accuracy: 0.1471 - val_loss: 0.0741 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0707 - accuracy: 0.1176 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.0718 - accuracy: 0.1176 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0710 - accuracy: 0.1029 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0678 - accuracy: 0.1324 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0730 - accuracy: 0.0735 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0710 - accuracy: 0.1029 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0700 - accuracy: 0.0735 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0731 - accuracy: 0.0735 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0696 - accuracy: 0.1765 - val_loss: 0.0750 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0741 - accuracy: 0.1029 - val_loss: 0.0752 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0666 - accuracy: 0.2206 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.0763 - accuracy: 0.1471 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0735 - accuracy: 0.1471 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0697 - accuracy: 0.1176 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0675 - accuracy: 0.0735 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0756 - accuracy: 0.1324 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0730 - accuracy: 0.1765 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0609 - accuracy: 0.2206 - val_loss: 0.0743 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0757 - accuracy: 0.0882 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0677 - accuracy: 0.1471 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0715 - accuracy: 0.1324 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0682 - accuracy: 0.1912 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0658 - accuracy: 0.2206 - val_loss: 0.0752 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.0675 - accuracy: 0.1618 - val_loss: 0.0753 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0678 - accuracy: 0.0735 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0687 - accuracy: 0.1618 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 169ms/step - loss: 0.0722 - accuracy: 0.0882 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0695 - accuracy: 0.1029 - val_loss: 0.0745 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0730 - accuracy: 0.1471 - val_loss: 0.0742 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0651 - accuracy: 0.1324 - val_loss: 0.0744 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0758 - accuracy: 0.1176 - val_loss: 0.0747 - val_accuracy: 0.0882\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0688 - accuracy: 0.1324 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0784 - accuracy: 0.0735 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0705 - accuracy: 0.0588 - val_loss: 0.0747 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0778 - accuracy: 0.0735 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0724 - accuracy: 0.1618 - val_loss: 0.0745 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0657 - accuracy: 0.1912 - val_loss: 0.0750 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0732 - accuracy: 0.1176 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0670 - accuracy: 0.1176 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.0749 - accuracy: 0.1471 - val_loss: 0.0751 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0696 - accuracy: 0.0735 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0722 - accuracy: 0.0882 - val_loss: 0.0748 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.0745 - accuracy: 0.1029 - val_loss: 0.0746 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0656 - accuracy: 0.1912 - val_loss: 0.0743 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 0.0697 - accuracy: 0.1324 - val_loss: 0.0746 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0709 - accuracy: 0.1618 - val_loss: 0.0749 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 0.0717 - accuracy: 0.1618 - val_loss: 0.0750 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 0.0690 - accuracy: 0.1618 - val_loss: 0.0746 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.0718 - accuracy: 0.1176 - val_loss: 0.0748 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.0769 - accuracy: 0.0588 - val_loss: 0.0747 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0707 - accuracy: 0.1176 - val_loss: 0.0745 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 0.0642 - accuracy: 0.2059 - val_loss: 0.0744 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 0.0736 - accuracy: 0.0882 - val_loss: 0.0741 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0701 - accuracy: 0.1471 - val_loss: 0.0738 - val_accuracy: 0.1471\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0710 - accuracy: 0.1618 - val_loss: 0.0736 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0673 - accuracy: 0.1618 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0649 - accuracy: 0.1618 - val_loss: 0.0737 - val_accuracy: 0.1176\n",
      "0:26:37.219982\n"
     ]
    }
   ],
   "source": [
    "begin_time = datetime.datetime.now()\n",
    "\n",
    "for i in range(0,10):\n",
    "    for batch_n in range(300):\n",
    "        X = load_images(X_train_batches[batch_n], resized_train_dir)\n",
    "        Y = encode(y_train_batches[batch_n])\n",
    "        test_images = load_images(X_test_batches[0], resized_train_dir)\n",
    "        test_labels = encode(y_test_batches[0])\n",
    "        history.append(model.fit(X, Y, validation_data=(test_images, test_labels)))\n",
    "        \n",
    "print(datetime.datetime.now() - begin_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_history = history_list_to_single(history)\n",
    "plt.plot(new_history['accuracy'], label='accuracy')\n",
    "plt.plot(new_history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"models/_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = listdir('../test_set/test_set')\n",
    "# resize_images(test_img, test_image_dir, resized_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batches = np.array_split(test_img, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set(model):\n",
    "    res = np.array([]).astype(int)\n",
    "    test_img = listdir('../test_set/test_set')\n",
    "    X_batches = np.array_split(test_img, 30)\n",
    "    for batch_n, batch in enumerate(X_batches):\n",
    "        X = load_images(batch, resized_test_dir)\n",
    "        res = np.concatenate((res, model.predict(X).argmax(axis=1)))\n",
    "    return res\n",
    "    \n",
    "    \n",
    "pred = predict_test_set(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7653,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "results[\"img_name\"] = test_img = listdir('../test_set/test_set')\n",
    "results[\"label\"] = pred\n",
    "pd.DataFrame.from_dict(results).to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
